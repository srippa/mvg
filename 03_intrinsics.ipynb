{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp intrinsics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intrinsics \n",
    "\n",
    "> The Intrinsics part of a camera model that transforms points to.from the 3D camera grame into the 2D image frame possibly with a distortion model. \n",
    "\n",
    "Need to check (and possible integrate) the [code from pixlib](https://github.com/cvg/pixloc/blob/master/pixloc/pixlib/geometry/wrappers.py#L224) that provides and camera model both for torch and numpy. The discussoions in [this tweet](https://twitter.com/pesarlin/status/1558087424445652998?s=27&t=ILeCIQvS1YTIJL8yMhYFMg) anre also useful. See [pinhole model in kornia](https://kornia.readthedocs.io/en/latest/geometry.camera.pinhole.html) - no distortions and use 4x4 homogenous representation all the way also with batch dimensions.\n",
    "\n",
    "Also look at [this code](https://github.com/princeton-vl/DPVO/blob/main/dpvo/projective_ops.py)\n",
    "\n",
    "Suggest a Pose API, Intrinsics API and camera API that include both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.utils import *    # to get patch\n",
    "from fastcore.test import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "from typing import Tuple\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric camera model\n",
    "\n",
    "The class `Intrinsics` models a pinhole camera with distortions. Useful books are:\n",
    "\n",
    "* The book [Computer Vision: Algorithms and Applications, 2nd ed.](http://szeliski.org/Book/),  [Richard Szeliski](https://szeliski.org/RichardSzeliski.htm), 2022 that can be freely downloaded.\n",
    "* [Multiple View Geometry in Computer Vision, 2nd ed.](https://www.robots.ox.ac.uk/~vgg/hzbook/), Hartley and Zisserman, , Cambridge University Press, 2004\n",
    "* [An Invitation to 3-D Vision (pdf)](https://www.eecis.udel.edu/~cer/arv/readings/old_mkss.pdf), Yi Ma, Jana Koˇseck´a, Stefano Soatto, Shankar Sastry, 2001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "SUPPORTED_CAMERA_MODELS = dict(\n",
    "    SIMPLE_PINHOLE = dict(id=0, n_params=3, params_str='f, cx, cy'), \n",
    "    PINHOLE        = dict(id=1, n_params=4,params_str='fx, fy, cx, cy'), \n",
    "    SIMPLE_RADIAL  = dict(id=2, n_params=4,params_str='f, cx, cy, k'), \n",
    "    RADIAL         = dict(id=3, n_params=5,params_str='f, cx, cy, k1, k2'), \n",
    "    OPENCV         = dict(id=4, n_params=8,params_str='fx, fy, cx, cy, k1, k2, p1, p2'), \n",
    "    OPENCV_FISHEYE = dict(id=5, n_params=8,params_str='fx, fy, cx, cy, k1, k2, k3, k4'), \n",
    "    FULL_OPENCV    = dict(id=6, n_params=12,params_str='fx, fy, cx, cy, k1, k2, p1, p2, k3, k4, k5, k6'), \n",
    "    FOV            = dict(id=7, n_params=5,params_str='fx, fy, cx, cy, omega'), \n",
    "    OPENCV5        = dict(id=-1, n_params=9,params_str='fx, fy, cx, cy, k1, k2, p1, p2, k3'),\n",
    "    UNKNOWN        = dict(id=-1, n_params=0,params_str='[]'), \n",
    ")\n",
    "\n",
    "def to_homogeneous(points):\n",
    "    # from https://github.com/cvg/pixloc/blob/master/pixloc/pixlib/geometry/utils.py\n",
    "    \"\"\"Convert N-dimensional points to homogeneous coordinates.\n",
    "    Args:\n",
    "        points: torch.Tensor or numpy.ndarray with size (..., N).\n",
    "    Returns:\n",
    "        A torch.Tensor or numpy.ndarray with size (..., N+1).\n",
    "    \"\"\"\n",
    "    if isinstance(points, torch.Tensor):\n",
    "        pad = points.new_ones(points.shape[:-1]+(1,))\n",
    "        return torch.cat([points, pad], dim=-1)\n",
    "    elif isinstance(points, np.ndarray):\n",
    "        pad = np.ones((points.shape[:-1]+(1,)), dtype=points.dtype)\n",
    "        return np.concatenate([points, pad], axis=-1)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "\n",
    "def from_homogeneous(points):\n",
    "    \"\"\"Remove the homogeneous dimension of N-dimensional points.\n",
    "    Args:\n",
    "        points: torch.Tensor or numpy.ndarray with size (..., N+1).\n",
    "    Returns:\n",
    "        A torch.Tensor or numpy ndarray with size (..., N).\n",
    "    \"\"\"\n",
    "    return points[..., :-1] / points[..., -1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class Intrinsics:\n",
    "    'Camera intrinsic model'\n",
    "    def __init__(self, \n",
    "                 camera_model_name: str,   # One of the keys in SUPPORTED_CAMERA_MODELS\n",
    "                 width: int,               # width of the image in pixels\n",
    "                 height: int,              # height of the image in pixels\n",
    "                 params: list):            # parameters, in COLMAP conventions\n",
    "        # prior_focal_length : 1 if we have confidence in the modelparameters and 0 if we do not trust the model parameters\n",
    "\n",
    "        if camera_model_name not in SUPPORTED_CAMERA_MODELS:\n",
    "            raise ValueError(f'Camera model [\"{camera_model_name}\"] not recognized as colmap camera model')\n",
    "        \n",
    "        param_names = SUPPORTED_CAMERA_MODELS[camera_model_name]['params_str'].split(',')\n",
    "        param_names = [p.strip() for p in param_names]\n",
    "        if len(param_names) != len(params):\n",
    "            raise ValueError(f'{camera_model_name} expectes {len(param_names)} parameters but got {len(params)}') \n",
    "\n",
    "        self._w = width\n",
    "        self._h = height\n",
    "\n",
    "        self._camera_model_name = camera_model_name\n",
    "        self._set_params(camera_model_name, params)\n",
    "\n",
    "    @staticmethod\n",
    "    def supported_camera_models():\n",
    "        print('List of supported camera models and their parameters')\n",
    "        print(55*'_')\n",
    "        for m in SUPPORTED_CAMERA_MODELS:\n",
    "            p = SUPPORTED_CAMERA_MODELS[m]['params_str']\n",
    "            print(f'{m:20}: {p}')\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        s  = f'Camera: {self.camera_model_name}\\n'\n",
    "        s += f'  w,h={self.width,self.height}\\n'\n",
    "        s += f'  params: {self.params}\\n'\n",
    "        s += f'  cx,cy= ({self.cx},{self.cy})\\n'\n",
    "        s += f'  fx,fy= ({self.fx},{self.fy})\\n'\n",
    "        s += f'  distortions: {self.distortions}\\n'\n",
    "\n",
    "\n",
    "        return s\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    @staticmethod\n",
    "    def from_pinhole_model(fx: float,   # Focal length (x) in pixels\n",
    "                           fy: float,   # Focal length (y) in pixels. fy might be equal to fx (SIMPLE_PINHOLE model) or different (PINHOLE model)\n",
    "                           cx:float,    # Camera center (x) in pixels\n",
    "                           cy: float,   # Camera center (y) in pixels\n",
    "                           width: int,  # Image width in pixels\n",
    "                           height: int  # Image height in pixels\n",
    "                           ) -> 'Intrinsics':\n",
    "        'Contructing camera intrinsics model from opencv compatible data'\n",
    "        if fx == fy:\n",
    "            camera_model_name = 'SIMPLE_PINHOLE'\n",
    "            params = [fx, cx, cy]\n",
    "        else:\n",
    "            camera_model_name = 'PINHOLE'\n",
    "            params = [fx, fy, cx, cy]\n",
    "\n",
    "        return Intrinsics(camera_model_name,width, height, params)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def from_opencv_model(K: np.ndarray, # 3x3 camera matrix\n",
    "                          distortions: np.ndarray, # distortion array as produced by OpenCv\n",
    "                          width: int, # Camera width in pixels\n",
    "                          height: int # Camera height in pixels\n",
    "                         ) -> 'Intrinsics':\n",
    "        'Contructing camera intrinsics model from opencv compatible data'\n",
    "        if not isinstance(distortions, list):\n",
    "            if len(distortions.shape) == 2:\n",
    "                distortions = distortions.squeeze()\n",
    "            distortions= distortions.tolist()\n",
    "     \n",
    "        fx = K[0,0]\n",
    "        cx = K[0,2]\n",
    "        fy = K[1,1]\n",
    "        cy = K[1,2]\n",
    "\n",
    "        params = [fx, fy, cx, cy]\n",
    "        if len(distortions) == 4:\n",
    "            camera_model_name = 'OPENCV'\n",
    "            params += distortions\n",
    "        elif len(distortions) == 5:\n",
    "            camera_model_name = 'OPENCV5'\n",
    "            params += distortions\n",
    "        elif len(distortions) == 8:\n",
    "            camera_model_name = 'FULL_OPENCV'\n",
    "            params += distortions\n",
    "        else:\n",
    "            raise ValueError(f'Do not support opencv model with {len(distortions)} parameters')\n",
    "\n",
    "        return Intrinsics(camera_model_name,width, height, params)\n",
    "\n",
    "    @staticmethod\n",
    "    def from_opencv_fisheye_model(K: np.ndarray, # 3x3 camera matrix\n",
    "                          distortions: np.ndarray, # distortion array for OpenCv fisheye model, should consist of 4 distrortion parameters\n",
    "                          width: int, # Camera width in pixels\n",
    "                          height: int # Camera height in pixels\n",
    "                         ) -> 'Intrinsics':\n",
    "        'Contructing camera intrinsics model from data compatible with opencv fisheye model'\n",
    "        if not isinstance(distortions, list):\n",
    "            if len(distortions.shape) == 2:\n",
    "                distortions = distortions.squeeze()\n",
    "            distortions= distortions.tolist()\n",
    "     \n",
    "        fx = K[0,0]\n",
    "        cx = K[0,2]\n",
    "        fy = K[1,1]\n",
    "        cy = K[1,2]\n",
    "\n",
    "        params = [fx, fy, cx, cy]\n",
    "        if len(distortions) == 4:\n",
    "            camera_model_name = 'OPENCV'\n",
    "            params += distortions\n",
    "        else:\n",
    "            raise ValueError(f'Do not support fisheye-opencv model with {len(distortions)} parameters')\n",
    "\n",
    "        return Intrinsics(camera_model_name,width, height, params)\n",
    "\n",
    "    @staticmethod\n",
    "    def from_test_model(as_full_opencv=False):\n",
    "        'Contructing camera intrinsics model from opencv calibration tutorial'\n",
    "        w, h = 640, 480 \n",
    "\n",
    "        distortions = np.array(\n",
    "            [\n",
    "            [-2.6637260909660682e-01], \n",
    "            [-3.8588898922304653e-02], \n",
    "            [1.7831947042852964e-03], \n",
    "            [-2.8122100441115472e-04], \n",
    "            [2.3839153080878486e-01]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if as_full_opencv:\n",
    "            distortions = np.array(\n",
    "                [\n",
    "                [-2.6637260909660682e-01], \n",
    "                [-3.8588898922304653e-02], \n",
    "                [1.7831947042852964e-03], \n",
    "                [-2.8122100441115472e-04], \n",
    "                [2.3839153080878486e-01],\n",
    "                [0.0],\n",
    "                [0.0],\n",
    "                [0.0]\n",
    "                ]\n",
    "        )\n",
    "\n",
    "        mtx = np.array(\n",
    "            [\n",
    "                [5.3591573396163199e+02, 0.,                     3.4228315473308373e+02],\n",
    "                [0.,                     5.3591573396163199e+02, 2.3557082909788173e+02],\n",
    "                [0.,                     0.,                     1.]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return Intrinsics.from_opencv_model(mtx,distortions,w, h)\n",
    "\n",
    "    #----------------------------------------------------------\n",
    "    # Access functions\n",
    "    #----------------------------------------------------------\n",
    "    @property\n",
    "    def camera_model_name(self) -> str:\n",
    "        'Returns the name of the camera model, e.g. `OPENCV`'\n",
    "        return self._camera_model_name\n",
    "\n",
    "    @property\n",
    "    def fx(self):\n",
    "        'Returns the (x) focal point in pixels'\n",
    "        return self._K[0,0]\n",
    "\n",
    "    @property\n",
    "    def fy(self):\n",
    "        'Returns the (y) forcal point in pixels'\n",
    "        return self._K[1,1]\n",
    "\n",
    "    @property\n",
    "    def cx(self):\n",
    "        'Returns the x coordinate of the camera center in pixels'\n",
    "        return self._K[0,2]\n",
    "\n",
    "    @property\n",
    "    def cy(self):\n",
    "        'Returns the y coordinate of the camera center in pixels'\n",
    "        return self._K[1,2]\n",
    "\n",
    "    @property\n",
    "    def w(self):\n",
    "        'Returns the width of image, same as calling to the `width` method'\n",
    "        return self._w\n",
    "\n",
    "    @property\n",
    "    def width(self):\n",
    "        'Returns the width of image, same as calling to the `w` method'\n",
    "        return self._w\n",
    "\n",
    "    @property\n",
    "    def h(self):\n",
    "        'Returns the height of image, same as calling to the `height` method'\n",
    "        return self._h\n",
    "\n",
    "    @property\n",
    "    def height(self):\n",
    "        'Returns the height of image, same as calling to the `h` method'\n",
    "        return self._h\n",
    "\n",
    "    def is_single_focal_lenght(self):\n",
    "        return 'SIMPLE' in self.camera_model_name\n",
    "\n",
    "    @property\n",
    "    def K(self) -> np.ndarray:\n",
    "        'Return the 4x4 camera matrix in homogenous coordinates'\n",
    "        return self._K\n",
    "\n",
    "    @property\n",
    "    def K_inv(self) -> np.ndarray:\n",
    "        'Return the 4x4 inverse of camera matrix in homogenous coordinates'\n",
    "        return self._K_inv\n",
    "\n",
    "    @property\n",
    "    def K_3(self) -> np.ndarray:\n",
    "        'Return the 3x3 camera matrix in npn homogenous coordinates'\n",
    "        return self._K[:3,:3]\n",
    "\n",
    "    @property\n",
    "    def K_3_inv(self) -> np.ndarray:\n",
    "        'Return the 3x3 inverse of the camera matrix in npn homogenous coordinates'\n",
    "        return self._K_3_inv\n",
    "\n",
    "    @property\n",
    "    def distortions(self) -> np.ndarray:\n",
    "        'Returns 1D distortion array'\n",
    "        return self._distortions\n",
    "\n",
    "    def get_fov(self) -> edict:\n",
    "        'Get horizontal and vertical field of view of the canera, in degrees'\n",
    "        # Zeliltsky 2.60\n",
    "        fovx = 2 * np.rad2deg(np.arctan2(self.width , (2 * self.fx)))\n",
    "        fovy = 2 * np.rad2deg(np.arctan2(self.height , (2 * self.fy)))\n",
    "\n",
    "        return edict(fovx=fovx, fovy=fovy)\n",
    "\n",
    "    @property\n",
    "    def params(self) -> list:\n",
    "        'Get list of parametes as expected in the consrtructor for the given camera model'\n",
    "        if self.is_single_focal_lenght():\n",
    "            cp = [self.fx, self.cx, self.cy]\n",
    "        else:\n",
    "            cp = [self.fx, self.fy, self.cx, self.cy]\n",
    "\n",
    "        p = cp + [float(d) for d in self.distortions]\n",
    "        return p\n",
    "\n",
    "\n",
    "    #----------------------------------------------------------\n",
    "    # operations\n",
    "    #----------------------------------------------------------    \n",
    "    def scale(self, \n",
    "              scale_by: Tuple     #  Sacle factors as (scale_width, scale_height)\n",
    "               ) -> 'Intrinsics':  # Intrinsics for  camera producing the scaled image\n",
    "        'Update Intrinsicss after scaling an image '\n",
    "        scale_w = scale_by[0]\n",
    "        scale_h = scale_by[1]\n",
    " \n",
    "        new_width = int(self.width*scale_w + 0.5)\n",
    "        new_height = int(self.height*scale_h + 0.5)\n",
    "\n",
    "        fx  = self.fx * scale_w    # fx\n",
    "        fy  = self.fy * scale_h    # fy\n",
    " \n",
    "        cx  = self.cx * scale_w    # cx\n",
    "        cy  = self.cy * scale_h    # cy\n",
    "\n",
    "        # COLMAP conventions\n",
    "        # cx  = (self.cx+0.5) * scale_w - 0.5   # cx\n",
    "        # cy  = (self.cy+0.5) * scale_h - 0.5   # cy\n",
    "\n",
    "        new_params = self._get_params_to_new_cx_cy_fx_fy(cx, cy, fx, fy)\n",
    "\n",
    "        return Intrinsics(\n",
    "            camera_model_name=self.camera_model_name, \n",
    "            width=new_width, \n",
    "            height=new_height, \n",
    "            params=new_params\n",
    "        )\n",
    "\n",
    "\n",
    "    def resize(self, \n",
    "               new_size: Tuple     # New size as (new_width, new_height)\n",
    "               ) -> 'Intrinsics':  # Intrinsics for the camera producing the resized image\n",
    "        'Update Intrinsicss after resizing an image '\n",
    "        new_width = new_size[0]\n",
    "        new_height = new_size[1]\n",
    "        scale_w = new_width / self.width\n",
    "        scale_h = new_height / self.height\n",
    "        return self.scale(scale_by=(scale_w, scale_h))\n",
    "\n",
    "    # def crop(self, left_top: Tuple[float], size: Tuple[int]):\n",
    "    # from https://github.com/cvg/pixloc/blob/65a51a7300a55d0b933dd13b6d1d7c1e6ef775d5/pixloc/pixlib/geometry/wrappers.py\n",
    "    #         '''Update the camera parameters after cropping an image.'''\n",
    "    #         left_top = self._data.new_tensor(left_top)\n",
    "    #         size = self._data.new_tensor(size)\n",
    "    #         data = torch.cat([\n",
    "    #             size,\n",
    "    #             self.f,\n",
    "    #             self.c - left_top,\n",
    "    #             self.dist], -1)\n",
    "    #         return self.__class__(data)\n",
    "\n",
    "    def crop(self, \n",
    "             top_left: Tuple[float], # Top left pixel of cropped image as (x,y)\n",
    "             crop_size: Tuple[int]   # Size of cropped bbox (size_x, size_y)\n",
    "             ) -> 'Intrinsics':      # Intrinsics for the camera producing the cropped image\n",
    "        'Update Intrinsicss after cropping an image '\n",
    "\n",
    "        new_cx = self.cx -  top_left[0]   \n",
    "        new_cy = self.cy - top_left[1]  \n",
    "\n",
    "        new_width = crop_size[0]\n",
    "        new_height =crop_size[1]\n",
    "\n",
    "        new_params = self._get_params_to_new_cx_cy_fx_fy(new_cx, new_cy, self.fx, self.fx)\n",
    "\n",
    "        return Intrinsics(\n",
    "            camera_model_name=self.camera_model_name, \n",
    "            width=new_width, \n",
    "            height=new_height, \n",
    "            params=new_params\n",
    "        )\n",
    "\n",
    "    #----------------------------------------------------\n",
    "    # Undistrortion\n",
    "    #----------------------------------------------------\n",
    "    def get_undistort_camera(self, \n",
    "                             alpha: float    # A number between 0 (all pixels in the undistorted image are valid) and 1 (all source images are retained but there are some black pixels)\n",
    "                             ) -> 'Intrinsics':     # A PINHOLE camera model\n",
    "        'Update Intrinsicss for camera producing the undistorted image/points '\n",
    "        # OpenCv function cvGetOptimalNewCameraMatrix\n",
    "        #   See cvGetOptimalNewCameraMatrix in line 2714 of https://github.com/opencv/opencv/blob/4.x/modules/calib3d/src/calibration.cpp\n",
    "        #   See https://docs.opencv.org/3.3.0/dc/dbb/tutorial_py_calibration.html\n",
    "        # COLMAP\n",
    "        #   See https://github.com/colmap/colmap/blob/dev/src/base/undistortion.h\n",
    "        #     alpha is called blank_pixels\n",
    "\n",
    "        outer, inner = self._icv_get_rectangles()\n",
    "\n",
    "        new_image_width = self.width\n",
    "        new_image_height = self.height\n",
    "   \n",
    "        # Projection mapping inner rectangle to viewport\n",
    "        fx0 = (new_image_width-1)/ inner.width\n",
    "        fy0 = (new_image_height-1)/ inner.height\n",
    "        cx0 = -fx0 * inner.x\n",
    "        cy0 = -fy0 * inner.y\n",
    "\n",
    "        # Projection mapping outer rectangle to viewport\n",
    "        fx1 = (new_image_width-1)/ outer.width\n",
    "        fy1 = (new_image_height-1)/ outer.height\n",
    "        cx1 = -fx1 * outer.x\n",
    "        cy1 = -fy1 * outer.y\n",
    "\n",
    "        # Interpolate between the two optimal projections\n",
    "        fx = fx0*(1 - alpha) + fx1*alpha\n",
    "        fy = fy0*(1 - alpha) + fy1*alpha\n",
    "        cx = cx0*(1 - alpha) + cx1*alpha\n",
    "        cy = cy0*(1 - alpha) + cy1*alpha\n",
    "\n",
    "        new_params = [fx,fy,cx,cy]\n",
    "        return Intrinsics(\n",
    "            camera_model_name='PINHOLE', \n",
    "            width=new_image_width, \n",
    "            height=new_image_height, \n",
    "            params=new_params\n",
    "        )\n",
    "  \n",
    "    def init_undistort_rectify_map(self, \n",
    "                                  alpha   # A number between 0 (all pixels in the undistorted image are valid) and 1 (all source images are retained but there are some black pixels)\n",
    "                                  ) -> edict: # dict with entries: \"pinhole_camera\", \"mapx\", \"mapy\"\n",
    "        'Return parameters needed for image undistortion plut the PINHOLE camera model of the undistorted image'\n",
    "        pinhole_camera = self.get_undistort_camera(alpha)\n",
    "\n",
    "        # See https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a\n",
    "        # code - line 64 in https://github.com/egonSchiele/OpenCV/blob/master/modules/imgproc/src/undistort.cpp\n",
    "        mapx = np.zeros((pinhole_camera.h, pinhole_camera.w))\n",
    "        mapy = np.zeros((pinhole_camera.h, pinhole_camera.w))\n",
    "\n",
    "        u = list(range(pinhole_camera.w))\n",
    "        v = list(range(pinhole_camera.h))\n",
    "        xv, yv = np.meshgrid(u, v)\n",
    "        xv = xv.reshape(pinhole_camera.h*pinhole_camera.w)\n",
    "        yv = yv.reshape(pinhole_camera.h*pinhole_camera.w)\n",
    "        points = np.stack([xv,yv]).T\n",
    "\n",
    "        # Undistort all points from the pinhole camera\n",
    "        p_undistorted = pinhole_camera.to_camera_points(points)  # from pinhole camera pixels to (undistorted) camera plane\n",
    "        p_distorted = self.distort_points(p_undistorted)         # Distort with the distortion  model of self\n",
    "        pix = self.to_image_points(p_distorted)                  # transform to image points of self\n",
    "\n",
    "        mapx = pix[:,0].reshape((pinhole_camera.h,pinhole_camera.w))   # maping of x pixels so mapx[u,v] is the x index of that pixel in self\n",
    "        mapy = pix[:,1].reshape((pinhole_camera.h,pinhole_camera.w))   # maping of y pixels so mapx[u,v] is the y index of that pixel in self\n",
    "\n",
    "        return edict(pinhole_camera=pinhole_camera, mapx=mapx, mapy=mapy)\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "    # project and unproject points functions:\n",
    "    #---------------------------------------------------------------------------\n",
    "    # camera2image_points\n",
    "    def camera2image_points(\n",
    "        self, \n",
    "        pc3d: np.ndarray                                   # 3D points in camera frame system with shape (N,3)\n",
    "        ) -> Tuple[np.ndarray, np.ndarray, np.ndarray] :   # A 2D point in the camera plane with shape (N,2), disparities with shape (N,1) and boolean valid mask with shape (N,)\n",
    "        'Project 3D points in the camera reference coordinate system into image coordinates'\n",
    "\n",
    "        assert(pc3d.shape[-1] == 3)\n",
    "\n",
    "        p_camera_plane_distorted, disparity, valid = self.project_and_distort_points(pc3d)\n",
    "        p_image = self.to_image_points(p_camera_plane_distorted)\n",
    "        return p_image, disparity, valid\n",
    "\n",
    "    def project_and_distort_points(\n",
    "        self, \n",
    "        pc3d: np.ndarray                                   # 3D points in camera frame system with shape (N,3)\n",
    "        ) -> Tuple[np.ndarray, np.ndarray, np.ndarray] :   # A 2D point in the camera plane with shape (N,2), disparities with shape (N,1) and boolean valid mask with shape (N,)\n",
    "        'Project 3D points in the camera reference coordinate system into 2D distorted points in the camera frame'\n",
    "\n",
    "        # project to camera plane (undistorted). Not used when we use OpenCV functions ProjectPoints since they project and undistort \n",
    "        # in a single function call\n",
    "        p_camera_plane_undistorted, disparity, valid = self.project_points(pc3d)\n",
    "\n",
    "        if self.camera_model_name in ['OPENCV', 'FULL_OPENCV']:\n",
    "            no_rot = np.array([[0.0], [0.0], [0.0]])\n",
    "            no_trans = np.array([[0.0], [0.0], [0.0]])\n",
    "            K = np.eye(3)\n",
    "            pimage_cv, _ =  cv2.projectPoints(\n",
    "                pc3d,                              # project to image\n",
    "                no_rot,\n",
    "                no_trans,\n",
    "                K,\n",
    "                self.distortions)\n",
    "            p_camera_plane_distorted = pimage_cv.squeeze(1)\n",
    "        elif self.camera_model_name ==  'OPENCV_FISHEYE':\n",
    "            no_rot = np.array([[0.0], [0.0], [0.0]])\n",
    "            no_trans = np.array([[0.0], [0.0], [0.0]])\n",
    "            K = np.eye(3)\n",
    "            p_camera_plane_distorted, _ =  cv2.fisheye.projectPoints(\n",
    "                pc3d,                              # project to image\n",
    "                no_rot,\n",
    "                no_trans,\n",
    "                K,\n",
    "                self.distortions)\n",
    "            p_camera_plane_distorted = pimage_cv.squeeze(1)\n",
    "        else:\n",
    "            p_camera_plane_distorted = self.distort_points(p_camera_plane_undistorted)    \n",
    "\n",
    "        return p_camera_plane_distorted, disparity, valid\n",
    "\n",
    "    def project_points(\n",
    "        self, \n",
    "        pc3d: np.ndarray,                                  # 3D points in camera frame, with shape (N,3) \n",
    "        projection_type: str = 'perspective'     # Projection type\n",
    "        ) -> Tuple[np.ndarray, np.ndarray, np.ndarray] :   # A 2D point in the camera plane with shape (N,2), disparities with shape (N,1) and boolean valid mask with shape (N,)\n",
    "        'Project 3D points in camera frame to 2D points in the camera plane'\n",
    "        eps = 1e-3\n",
    "\n",
    "        z = pc3d[..., -1]\n",
    "        valid = z > eps\n",
    "        z = z.clip(min=eps)\n",
    "        disparity = 1.0 / np.expand_dims(z,-1)\n",
    "        p2d = pc3d[..., :-1] * disparity\n",
    "        return p2d, disparity, valid\n",
    "\n",
    "    def distort_points(\n",
    "        self, \n",
    "        p_cam_undistorted: np.ndarray # 2D Undistorted point in the camera plane with shape (N,2)\n",
    "        ) -> np.ndarray:              # 2D distorted point in the camera plane with shape (N,2)\n",
    "        'Distort points in the camera plane'\n",
    "        # see line 888 in https://github.com/colmap/colmap/blob/dev/src/base/camera_models.h\n",
    "        camera_model_name = self.camera_model_name\n",
    "        distortions = self.distortions\n",
    "        if len(distortions) == 0:\n",
    "            return  p_cam_distorted.copy()\n",
    "\n",
    "\n",
    "        if self.camera_model_name in ['OPENCV', 'FULL_OPENCV','OPENCV_FISHEYE']:\n",
    "            raise ValueError(f'Function distort_points can not be used for OpenCv models since the do projection and distortion in a single function call, thus require 3D points as input')\n",
    "        elif camera_model_name == 'SIMPLE_RADIAL':\n",
    "            k1 = distortions[0]\n",
    "            xd, yd = p_cam_undistorted[..., 0], p_cam_undistorted[..., 1]\n",
    "\n",
    "            x2 = xd*xd\n",
    "            y2 = yd*yd\n",
    "            r2 = x2 + y2\n",
    "            a = 1.0 + k1*r2  \n",
    "            xu = a*xd \n",
    "            yu = a*yd \n",
    "    \n",
    "            p_cam_distorted = np.stack([xu,yu], axis=-1)\n",
    "            return p_cam_distorted\n",
    "        elif camera_model_name == 'RADIAL':\n",
    "            k1 = distortions[0]\n",
    "            k2 = distortions[1]\n",
    "\n",
    "            xd, yd = p_cam_undistorted[..., 0], p_cam_undistorted[..., 1]\n",
    "\n",
    "            x2 = xd*xd\n",
    "            y2 = yd*yd\n",
    "            r2 = x2 + y2\n",
    "            r4 = r2*r2\n",
    "\n",
    "            a = 1.0 + k1*r2  + k2*r4 \n",
    "            xu = a*xd \n",
    "            yu = a*yd \n",
    "    \n",
    "            p_cam_distorted = np.stack([xu,yu], axis=-1)\n",
    "\n",
    "            return p_cam_distorted\n",
    "        elif camera_model_name == 'OPENCV5':\n",
    "            # See https://learnopencv.com/understanding-lens-distortion/\n",
    "            k1 = distortions[0]\n",
    "            k2 = distortions[1]\n",
    "            p1 = distortions[2]\n",
    "            p2 = distortions[3] \n",
    "            k3 = distortions[4]\n",
    "\n",
    "            xd, yd = p_cam_undistorted[..., 0], p_cam_undistorted[..., 1]\n",
    "\n",
    "            x2 = xd*xd\n",
    "            y2 = yd*yd\n",
    "            xy = xd*yd\n",
    "            r2 = x2 + y2\n",
    "            r4 = r2*r2\n",
    "            r6 = r2*r4\n",
    "\n",
    "            a = 1.0 + k1*r2  + k2*r4 + k3*r6\n",
    "            xu = a*xd + 2.0*p1*xy + p2*(r2 + 2.0*x2)\n",
    "            yu = a*yd + p1*(r2+2.0*y2) + 2.0*p2*xy\n",
    "    \n",
    "            p_cam_distorted = np.stack([xu,yu], axis=-1)\n",
    "\n",
    "            return p_cam_distorted\n",
    "        else:\n",
    "            raise ValueError(f'distort_points not impelmented for camera model [{self.camera_model_name}]')\n",
    "\n",
    "    def to_image_points(\n",
    "        self,\n",
    "        pc_distorted: np.ndarray  # 2D points in the camera plane with shape (N,2)\n",
    "        ) -> np.ndarray:          # 2D points in the image plane with shape (N,2)\n",
    "        'Transform points from the camera plane to the image plane, using the camera matrix K'\n",
    " \n",
    "        pcd_h = to_homogeneous(pc_distorted)\n",
    "        pix_T = pcd_h @ self.K_3.T\n",
    "        return pix_T[..., :-1]\n",
    "\n",
    "    #----------------\n",
    "    # image2camera\n",
    "    #----------------\n",
    "    def to_camera_points(\n",
    "        self, \n",
    "        pu: np.ndarray,                  # points in the image plane, shape is (N,2)\n",
    "        ) -> np.ndarray: # points in distorted camera plane, shape (N,2)\n",
    "        'Transform pixel image coordinates into the distorted camera plane'\n",
    "        pu_h = to_homogeneous(pu)\n",
    "        pd_h_T = pu_h @ self.K_3_inv.T\n",
    "        pd = pd_h_T[..., :-1]          \n",
    "        return pd \n",
    "\n",
    "\n",
    "    def undistort(self, \n",
    "                  pc_distorted: np.ndarray  # Distorted points in the camera plane, shape (N,2)\n",
    "                  ) -> np.ndarray:          # Undistorted points in the image plane\n",
    "        'Undistort points in the image plane using the inverse of the distortion model for that camera model'\n",
    "        # see line 565 in https://github.com/colmap/colmap/blob/dev/src/base/camera_models.h\n",
    "        eps = np.finfo(np.float64).eps\n",
    "        N = pc_distorted.shape[0]\n",
    "\n",
    "        kNumIterations = 17\n",
    "        kMaxStepNorm = np.float32(1e-10)\n",
    "        kRelStepSize = np.float32(1e-6)\n",
    "\n",
    "        J = np.zeros((N,2,2))\n",
    "        p0 = pc_distorted.copy()\n",
    "        x = pc_distorted.copy()\n",
    "        for i in range(kNumIterations):\n",
    "            x0 = x[..., 0]\n",
    "            x1 = x[..., 1]\n",
    "            step0 = np.maximum(eps, kRelStepSize * x0)\n",
    "            step1 = np.maximum(eps, kRelStepSize * x1)\n",
    "\n",
    "            dx = self.distort_points(x)\n",
    "\n",
    "            # Compute numerical Jacobian\n",
    "            dx_0b = self.distort_points(np.array([x0 - step0, x1]).T)\n",
    "            dx_0f = self.distort_points(np.array([x0 + step0, x1]).T)\n",
    "            dx_1b = self.distort_points(np.array([x0        , x1 - step1]).T)\n",
    "            dx_1f = self.distort_points(np.array([x0        , x1 + step1]).T)\n",
    "            J[:,0, 0] = 1 + (dx_0f[...,0] - dx_0b[...,0]) / (2 * step0)\n",
    "            J[:,0, 1] = (dx_1f[...,0] - dx_1b[...,0]) / (2 * step1)\n",
    "            J[:,1, 0] = (dx_0f[...,1] - dx_0b[...,1]) / (2 * step0)\n",
    "            J[:,1, 1] = 1 + (dx_1f[...,1] - dx_1b[...,1]) / (2 * step1)\n",
    "    \n",
    "            jac_invs = np.linalg.inv(J)\n",
    "            for i in range(N):\n",
    "                jinv = jac_invs[i,...]\n",
    "                rhs = (dx - p0)[i,:]\n",
    "                sx = jinv @ rhs\n",
    "                x[i,:] -= sx\n",
    " \n",
    "\n",
    "                                                    \n",
    "        return  x   # undistorted\n",
    "\n",
    "\n",
    "    def _set_params(self, camera_model_name, params):\n",
    "        param_names = SUPPORTED_CAMERA_MODELS[camera_model_name]['params_str'].split(',')\n",
    "        param_names = [p.strip() for p in param_names]\n",
    "        if len(param_names) != len(params):\n",
    "            raise ValueError(f'{camera_model_name} expectes {len(param_names)} parameters but got {len(params)}') \n",
    "\n",
    "        self._params = params\n",
    "        \n",
    "        # First names should be one of f,fx,fy,cx,cy\n",
    "        camera_matrix_components = ['f','fx','fy','cx','cy']\n",
    "        dlist = []\n",
    "        cp = edict(fx=0.,fy=0.,cx=0.,cy=0.)\n",
    "        for i, (name, val) in enumerate(zip(param_names,params)):\n",
    "#             print(name,val)\n",
    "            if name not in camera_matrix_components:\n",
    "                dlist.append(val)\n",
    "            elif name == 'f': \n",
    "                cp.fx = val\n",
    "                cp.fy = val\n",
    "            else:\n",
    "                cp[name] = val\n",
    "\n",
    "        self._K = np.array(\n",
    "            [\n",
    "                [cp.fx, 0.0,     cp.cx,     0.0],\n",
    "                [0.0,     cp.fy, cp.cy,     0.0],\n",
    "                [0.0,     0.0,     1.0,     0.0 ],\n",
    "                [0.0,     0.0,     0.0,     1.0 ]\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "        self._K_inv = np.linalg.inv(self._K)\n",
    "        self._K_3_inv = np.linalg.inv(self._K[:3,:3])\n",
    "\n",
    "        self._distortions = np.array(dlist, dtype=np.float64)\n",
    "\n",
    "    \n",
    "    def _get_params_to_new_cx_cy_fx_fy(self, new_cx, new_cy, new_fx, new_fy):\n",
    "        if self.is_single_focal_lenght():\n",
    "            cp = [new_fx, new_cx, new_cy]\n",
    "        else:\n",
    "            cp =  [new_fx, new_fy, new_cx, new_cy]\n",
    "\n",
    "        p = cp + [float(d) for d in self.distortions]\n",
    "        return p\n",
    "\n",
    "\n",
    "    def _icv_get_rectangles(self):\n",
    "        # see icvGetRectangles, line 2460 in https://github.com/opencv/opencv/blob/4.x/modules/calib3d/src/calibration.cpp\n",
    "        N = 9\n",
    "        x_step = self.w / (N-1)\n",
    "        y_step = self.h / (N-1)\n",
    "\n",
    "        points = np.zeros((N*N, 2))\n",
    "        k= 0\n",
    "        for y in range(N):\n",
    "            yp = y*y_step\n",
    "            for x in range(N):\n",
    "                xp = x*x_step\n",
    "                points[k] = np.array([xp,yp])\n",
    "                k += 1\n",
    "\n",
    "        p_camere_distorted = self.to_camera_points(points)\n",
    "        p_camera_undistorted = self.undistort(p_camere_distorted)\n",
    "\n",
    "\n",
    "        k= 0\n",
    "        xu_left = []\n",
    "        xu_right = []\n",
    "        yu_bottom = [] \n",
    "        yu_top = []         \n",
    "\n",
    "        for y in range(N):\n",
    "            yp = y*y_step\n",
    "            for x in range(N):\n",
    "                xp = x*x_step\n",
    "                pu = p_camera_undistorted[k]\n",
    "                k += 1\n",
    "                if x == 0: xu_left.append(pu[0])\n",
    "                if x == N-1: xu_right.append(pu[0])\n",
    "                if y == 0: yu_top.append(pu[1])\n",
    "                if y == N-1: yu_bottom.append(pu[1])\n",
    "\n",
    "        pmax = np.max(p_camera_undistorted, axis=0)\n",
    "        pmin = np.min(p_camera_undistorted, axis=0)\n",
    "        outer = edict(x=pmin[0], y=pmin[1], width=pmax[0]-pmin[0], height=pmax[1]-pmin[1])\n",
    "\n",
    "\n",
    "        xmin_i = np.max(xu_left)\n",
    "        xmax_i = np.min(xu_right)\n",
    "        ymin_i = np.max(yu_top)\n",
    "        ymax_i = np.min(yu_bottom)\n",
    "        inner = edict(x=xmin_i, y=ymin_i, width=xmax_i-xmin_i, height=ymax_i-ymin_i)\n",
    "\n",
    "        return outer, inner\n",
    "\n",
    "    def to_dict(self):\n",
    "        return self.as_dict()\n",
    "\n",
    "    def as_dict(self):\n",
    "        asdict = dict(\n",
    "            width=self.width,\n",
    "            height=self.height,\n",
    "            camera_model_name=self.camera_model_name,\n",
    "            params=[float(p) for p in self.params.tolist()]\n",
    "        )\n",
    "        return asdict\n",
    "\n",
    "#     def to_json(self, json_file):\n",
    "#         write_json_file(self.as_dict(), json_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intrinsics API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supported camera models\n",
    "\n",
    "This is the list of all supported camera models. Each item includes tha name of the camera model, e.g. `SIMPLE_RADIAL` and list of expected parameters as handled by `Intrinsics`. All camera models of [COLMAP](https://github.com/colmap/colmap/blob/master/src/base/camera_models.h) are supported and some more, as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of supported camera models and their parameters\n",
      "_______________________________________________________\n",
      "SIMPLE_PINHOLE      : f, cx, cy\n",
      "PINHOLE             : fx, fy, cx, cy\n",
      "SIMPLE_RADIAL       : f, cx, cy, k\n",
      "RADIAL              : f, cx, cy, k1, k2\n",
      "OPENCV              : fx, fy, cx, cy, k1, k2, p1, p2\n",
      "OPENCV_FISHEYE      : fx, fy, cx, cy, k1, k2, k3, k4\n",
      "FULL_OPENCV         : fx, fy, cx, cy, k1, k2, p1, p2, k3, k4, k5, k6\n",
      "FOV                 : fx, fy, cx, cy, omega\n",
      "OPENCV5             : fx, fy, cx, cy, k1, k2, p1, p2, k3\n",
      "UNKNOWN             : []\n"
     ]
    }
   ],
   "source": [
    "Intrinsics.supported_camera_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct camera model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization\n",
    "Call to the constructor of the class with parameters such as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Camera: OPENCV5\n",
       "  w,h=(640, 320)\n",
       "  params: [400.0, 410.0, 320.0, 160.0, 14.0, 15.0, 16.0, 17.0, 228.0]\n",
       "  cx,cy= (320.0,160.0)\n",
       "  fx,fy= (400.0,410.0)\n",
       "  distortions: [ 14.  15.  16.  17. 228.]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Intrinsics(\n",
    "    camera_model_name='OPENCV5',\n",
    "    width=640,\n",
    "    height=320,\n",
    "    params=[400, 410.0, 320, 160,14,15,16,17,228]\n",
    ")\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### Intrinsics.from_opencv_model\n",
       "\n",
       ">      Intrinsics.from_opencv_model (K:numpy.ndarray, distortions:numpy.ndarray,\n",
       ">                                    width:int, height:int)\n",
       "\n",
       "Contructing camera intrinsics model from opencv compatible data\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| K | ndarray | 3x3 camera matrix |\n",
       "| distortions | ndarray | distortion array as produced by OpenCv |\n",
       "| width | int | Camera width in pixels |\n",
       "| height | int | Camera height in pixels |\n",
       "| **Returns** | **Intrinsics** |  |"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construction functions\n",
    "show_doc(Intrinsics.from_opencv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### Intrinsics.from_opencv_fisheye_model\n",
       "\n",
       ">      Intrinsics.from_opencv_fisheye_model (K:numpy.ndarray,\n",
       ">                                            distortions:numpy.ndarray,\n",
       ">                                            width:int, height:int)\n",
       "\n",
       "Contructing camera intrinsics model from data compatible with opencv fisheye model\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| K | ndarray | 3x3 camera matrix |\n",
       "| distortions | ndarray | distortion array for OpenCv fisheye model, should consist of 4 distrortion parameters |\n",
       "| width | int | Camera width in pixels |\n",
       "| height | int | Camera height in pixels |\n",
       "| **Returns** | **Intrinsics** |  |"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Intrinsics.from_opencv_fisheye_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### Intrinsics.from_pinhole_model\n",
       "\n",
       ">      Intrinsics.from_pinhole_model (fx:float, fy:float, cx:float, cy:float,\n",
       ">                                     width:int, height:int)\n",
       "\n",
       "Contructing camera intrinsics model from opencv compatible data\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| fx | float | Focal length (x) in pixels |\n",
       "| fy | float | Focal length (y) in pixels. fy might be equal to fx (SIMPLE_PINHOLE model) or different (PINHOLE model) |\n",
       "| cx | float | Camera center (x) in pixels |\n",
       "| cy | float | Camera center (y) in pixels |\n",
       "| width | int | Image width in pixels |\n",
       "| height | int | Image height in pixels |\n",
       "| **Returns** | **Intrinsics** |  |"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Intrinsics.from_pinhole_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, consider the construction from an OpenCv model with 5 parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Camera: OPENCV5\n",
       "  w,h=(1280, 720)\n",
       "  params: [600.0, 600.0, 640.0, 360.0, -0.151960304, 0.560700273, -0.012823499, 0.0014177545, 5.23404322]\n",
       "  cx,cy= (640.0,360.0)\n",
       "  fx,fy= (600.0,600.0)\n",
       "  distortions: [-1.51960304e-01  5.60700273e-01 -1.28234990e-02  1.41775450e-03\n",
       "  5.23404322e+00]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width = 1280\n",
    "height = 720\n",
    "fx = 600\n",
    "fy = 600\n",
    "cx = 1280 /2\n",
    "cy = 720 /2\n",
    "K = np.array(\n",
    "    [\n",
    "        [fx, 0.0, cx],\n",
    "        [0.0, fy, cy],\n",
    "        [0.0,0.0,1.0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "distortions = [-1.51960304e-01,  5.60700273e-01, -1.28234990e-02,  1.41775450e-03, 5.23404322e+00]\n",
    "Intrinsics.from_opencv_model(K,distortions,width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### Intrinsics.from_test_model\n",
       "\n",
       ">      Intrinsics.from_test_model (as_full_opencv=False)\n",
       "\n",
       "Contructing camera intrinsics model from opencv calibration tutorial"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Intrinsics.from_test_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test model is taken form the [OpenCV calibration tutorial](https://docs.opencv.org/3.3.0/dc/dbb/tutorial_py_calibration.html) and the images used for calibrating the test model are given in  [this directory](https://github.com/opencv/opencv/tree/master/samples/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Camera: OPENCV5\n",
       "  w,h=(640, 480)\n",
       "  params: [535.915733961632, 535.915733961632, 342.28315473308373, 235.57082909788173, -0.2663726090966068, -0.03858889892230465, 0.0017831947042852964, -0.0002812210044111547, 0.23839153080878486]\n",
       "  cx,cy= (342.28315473308373,235.57082909788173)\n",
       "  fx,fy= (535.915733961632,535.915733961632)\n",
       "  distortions: [-0.26637261 -0.0385889   0.00178319 -0.00028122  0.23839153]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Intrinsics.from_test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera : OPENCV5, fx=400.0, fy=410.0, cx=320.0, cy=160.0, distortions=[ 14.  15.  16.  17. 228.]\n",
      "Camera width: 640, heigth: 320\n"
     ]
    }
   ],
   "source": [
    "print(f'Camera : {c.camera_model_name}, fx={c.fx}, fy={c.fy}, cx={c.cx}, cy={c.cy}, distortions={c.distortions}')\n",
    "print(f'Camera width: {c.w}, heigth: {c.h}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### Intrinsics.K\n",
       "\n",
       "\n",
       "\n",
       "Return the 4x4 camera matrix in homogenous coordinates"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Intrinsics.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### Intrinsics.K_inv\n",
       "\n",
       "\n",
       "\n",
       "Return the 4x4 inverse of camera matrix in homogenous coordinates"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Intrinsics.K_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### Intrinsics.K_3\n",
       "\n",
       "\n",
       "\n",
       "Return the 3x3 camera matrix in npn homogenous coordinates"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Intrinsics.K_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### Intrinsics.K_3_inv\n",
       "\n",
       "\n",
       "\n",
       "Return the 3x3 inverse of the camera matrix in npn homogenous coordinates"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Intrinsics.K_3_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homogenous camera matrix: \n",
      " [[400.   0. 320.   0.]\n",
      " [  0. 410. 160.   0.]\n",
      " [  0.   0.   1.   0.]\n",
      " [  0.   0.   0.   1.]], float64\n",
      "Non homogenous camera matrix: \n",
      " [[400.   0. 320.]\n",
      " [  0. 410. 160.]\n",
      " [  0.   0.   1.]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Homogenous camera matrix: \\n {c.K}, {c.K.dtype}')\n",
    "print(f'Non homogenous camera matrix: \\n {c.K_3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### Intrinsics.distortions\n",
       "\n",
       "\n",
       "\n",
       "Returns 1D distortion array"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Intrinsics.distortions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distortions: [ 14.  15.  16.  17. 228.], float64\n"
     ]
    }
   ],
   "source": [
    "print(f'Distortions: {c.distortions}, {c.distortions.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### Intrinsics.params\n",
       "\n",
       "\n",
       "\n",
       "Get list of parametes as expected in the consrtructor for the given camera model"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Intrinsics.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of camera model OPENCV5: [400.0, 410.0, 320.0, 160.0, 14.0, 15.0, 16.0, 17.0, 228.0]\n"
     ]
    }
   ],
   "source": [
    "print(f'Parameters of camera model {c.camera_model_name}: {c.params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### Intrinsics.get_fov\n",
       "\n",
       ">      Intrinsics.get_fov ()\n",
       "\n",
       "Get horizontal and vertical field of view of the canera, in degrees"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Intrinsics.get_fov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fovx': 61.683594005974356, 'fovy': 48.248686484809355}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Intrinsics.from_test_model().get_fov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Camera: OPENCV5\n",
       "  w,h=(640, 480)\n",
       "  params: [535.915733961632, 535.915733961632, 342.28315473308373, 235.57082909788173, -0.2663726090966068, -0.03858889892230465, 0.0017831947042852964, -0.0002812210044111547, 0.23839153080878486]\n",
       "  cx,cy= (342.28315473308373,235.57082909788173)\n",
       "  fx,fy= (535.915733961632,535.915733961632)\n",
       "  distortions: [-0.26637261 -0.0385889   0.00178319 -0.00028122  0.23839153]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_camera = Intrinsics.from_test_model()\n",
    "base_camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### Intrinsics.scale\n",
       "\n",
       ">      Intrinsics.scale (scale_by:Tuple)\n",
       "\n",
       "Update Intrinsicss after scaling an image \n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| scale_by | typing.Tuple | Sacle factors as (scale_width, scale_height) |\n",
       "| **Returns** | **Intrinsics** | **Intrinsics for  camera producing the scaled image** |"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Intrinsics.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss  0.5 0.5\n",
      "171.14157736654187 117.78541454894086\n",
      "267.957866980816 267.957866980816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Camera: OPENCV5\n",
       "  w,h=(320, 240)\n",
       "  params: [267.957866980816, 267.957866980816, 171.14157736654187, 117.78541454894086, -0.2663726090966068, -0.03858889892230465, 0.0017831947042852964, -0.0002812210044111547, 0.23839153080878486]\n",
       "  cx,cy= (171.14157736654187,117.78541454894086)\n",
       "  fx,fy= (267.957866980816,267.957866980816)\n",
       "  distortions: [-0.26637261 -0.0385889   0.00178319 -0.00028122  0.23839153]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_camera.scale((0.5,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### Intrinsics.resize\n",
       "\n",
       ">      Intrinsics.resize (new_size:Tuple)\n",
       "\n",
       "Update Intrinsicss after resizing an image \n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| new_size | typing.Tuple | New size as (new_width, new_height) |\n",
       "| **Returns** | **Intrinsics** | **Intrinsics for the camera producing the resized image** |"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Intrinsics.resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ss  0.375 0.5\n",
      "128.3561830249064 117.78541454894086\n",
      "200.968400235612 267.957866980816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Camera: OPENCV5\n",
       "  w,h=(240.0, 240.0)\n",
       "  params: [200.968400235612, 267.957866980816, 128.3561830249064, 117.78541454894086, -0.2663726090966068, -0.03858889892230465, 0.0017831947042852964, -0.0002812210044111547, 0.23839153080878486]\n",
       "  cx,cy= (128.3561830249064,117.78541454894086)\n",
       "  fx,fy= (200.968400235612,267.957866980816)\n",
       "  distortions: [-0.26637261 -0.0385889   0.00178319 -0.00028122  0.23839153]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_camera.resize((240,240))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### Intrinsics.crop\n",
       "\n",
       ">      Intrinsics.crop (top_left:Tuple[float], crop_size:Tuple[int])\n",
       "\n",
       "Update Intrinsicss after cropping an image \n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| top_left | typing.Tuple[float] | Top left pixel of cropped image as (x,y) |\n",
       "| crop_size | typing.Tuple[int] | Size of cropped bbox (size_x, size_y) |\n",
       "| **Returns** | **Intrinsics** | **Intrinsics for the camera producing the cropped image** |"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Intrinsics.crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Camera: OPENCV5\n",
       "  w,h=(200, 200)\n",
       "  params: [535.915733961632, 535.915733961632, 242.28315473308373, 135.57082909788173, -0.2663726090966068, -0.03858889892230465, 0.0017831947042852964, -0.0002812210044111547, 0.23839153080878486]\n",
       "  cx,cy= (242.28315473308373,135.57082909788173)\n",
       "  fx,fy= (535.915733961632,535.915733961632)\n",
       "  distortions: [-0.26637261 -0.0385889   0.00178319 -0.00028122  0.23839153]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_camera.crop(top_left=(100,100), crop_size=(200,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undistortion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### Intrinsics.get_undistort_camera\n",
       "\n",
       ">      Intrinsics.get_undistort_camera (alpha:float)\n",
       "\n",
       "Update Intrinsicss for camera producing the undistorted image/points \n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| alpha | float | A number between 0 (all pixels in the undistorted image are valid) and 1 (all source images are retained but there are some black pixels) |\n",
       "| **Returns** | **Intrinsics** | **A PINHOLE camera model** |"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Intrinsics.get_undistort_camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera: OPENCV5\n",
      "  w,h=(320, 240)\n",
      "  params: [267.957866980816, 267.957866980816, 171.14157736654187, 117.78541454894086, -0.2663726090966068, -0.03858889892230465, 0.0017831947042852964, -0.0002812210044111547, 0.23839153080878486]\n",
      "  cx,cy= (171.14157736654187,117.78541454894086)\n",
      "  fx,fy= (267.957866980816,267.957866980816)\n",
      "  distortions: [-0.26637261 -0.0385889   0.00178319 -0.00028122  0.23839153]\n",
      "\n",
      "Comparing impelementation of get_undistort_camera to OpenCv getOptimalNewCameraMatrix for different values of alpha\n"
     ]
    }
   ],
   "source": [
    "base_camera = Intrinsics.from_test_model().scale((0.5,0.5))\n",
    "print(base_camera)\n",
    "\n",
    "print('Comparing impelementation of get_undistort_camera to OpenCv getOptimalNewCameraMatrix for different values of alpha')\n",
    "mtx = base_camera.K_3\n",
    "errors_K = []\n",
    "for alpha in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "    new_matrix_cv, roi = cv2.getOptimalNewCameraMatrix(\n",
    "        base_camera.K_3,\n",
    "        base_camera.distortions,\n",
    "        (base_camera.w,base_camera.h),\n",
    "        alpha=alpha\n",
    "    )\n",
    "    # print(roi)\n",
    "\n",
    "    new_camera = base_camera.get_undistort_camera(alpha=alpha)\n",
    "\n",
    "    err_new_matrix = np.linalg.norm(new_camera.K_3-new_matrix_cv)\n",
    "    errors_K.append(err_new_matrix)\n",
    "\n",
    "assert np.any(np.array(errors_K) < 0.002), f'Large errors between OpenCV and \"get_undistort_camera\": [{errors_K}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "#### Intrinsics.init_undistort_rectify_map\n",
       "\n",
       ">      Intrinsics.init_undistort_rectify_map (alpha)\n",
       "\n",
       "Return parameters needed for image undistortion plut the PINHOLE camera model of the undistorted image\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| alpha |  | A number between 0 (all pixels in the undistorted image are valid) and 1 (all source images are retained but there are some black pixels) |\n",
       "| **Returns** | **EasyDict** | **dict with entries: \"pinhole_camera\", \"mapx\", \"mapy\"** |"
      ],
      "text/plain": [
       "<nbdev.showdoc.BasicMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Intrinsics.init_undistort_rectify_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for alpha in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "    r = base_camera.init_undistort_rectify_map(alpha=1.0)\n",
    "\n",
    "    opencv_mapx, opencv_mapy = cv2.initUndistortRectifyMap(\n",
    "        base_camera.K_3, \n",
    "        base_camera.distortions,\n",
    "        None,\n",
    "        r.pinhole_camera.K_3,\n",
    "        (r.pinhole_camera.w,r.pinhole_camera.h),\n",
    "        cv2.CV_32FC1\n",
    "    )\n",
    "\n",
    "    ex = np.linalg.norm(r.mapx-opencv_mapx)\n",
    "    ey = np.linalg.norm(r.mapy-opencv_mapy)\n",
    "    assert ex < 0.01, f'Assertion error (alpha={alpha}): Errors: mapx_opencv-mapx={ex}'\n",
    "    assert ey < 0.01, f'Assertion error (alpha={alpha}): Errors: mapy_opencv-mapy={ey}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_undistort_rectify_map(camera_inrinsics: Intrinsics, pinhole_camera: Intrinsics):\n",
    "    # See https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#ga7dfb72c9cf9780a347fbe3d1c47e5d5a\n",
    "    # code - line 64 in https://github.com/egonSchiele/OpenCV/blob/master/modules/imgproc/src/undistort.cpp\n",
    "    mapx = np.zeros((pinhole_camera.h, pinhole_camera.w))\n",
    "    mapy = np.zeros((pinhole_camera.h, pinhole_camera.w))\n",
    "    for u in range(pinhole_camera.w):\n",
    "        for v in range(pinhole_camera.h):\n",
    "            pi = np.array([float(u), float(v)])\n",
    "            p_undistorted = pinhole_camera.project_image_plane_to_camera_plane(pi)\n",
    "\n",
    "            p_distorted = camera_inrinsics.distort(p_undistorted)\n",
    "            pix = camera_inrinsics.project_camera_plane_to_image_plane(p_distorted)\n",
    "            mapx[v,u] = pix[0]\n",
    "            mapy[v,u] = pix[1]\n",
    "\n",
    "    return mapx, mapy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project and unproject points \n",
    "Points are represented in `homogenous` coordinates or in regular Eucledian coordinates. We will denote points in hompogenous coordinates with a `tilde` so a 3D point $P$ in homogenous coordinates will be denoted by $\\tilde{P}$. IN the same manner, 2D points will be written in small letters, such as $\\tilde{p}$ in 2D homogenous coordinates and $p$ in 2D Eucledian space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project points\n",
    "\n",
    "The function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Intrinsics.camera2image_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In homegenous coordinates we have\n",
    "$$\n",
    "\\tilde{p}_c = \\begin{pmatrix} x_c \\\\ y_c \\\\ z_c \\\\1  \\end{pmatrix}  \\Rightarrow \\tilde{p}_u = \\begin{pmatrix} u \\\\ v \\\\ \\tt{d}  \\end{pmatrix}\n",
    "$$\n",
    "where $\\tilde{p}_c$ is a 3D point in the camera coordinate system, $\\tilde{p}_u$ consists of the pixel cooridates of that point, `d` is the disparity. \n",
    "\n",
    "The function expects regular collection of 3D points as an array of shape (N,3) and returns:\n",
    "\n",
    "* 2D points in image plane, array of shape (N,2)\n",
    "* disparitiers (inverse depth), array of shape (N,2)\n",
    "* A `valid` boolean vector for indexing the valid points. 3D points for which $z$ is too close to zero are invalid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider two sets of 3D points in the camera coordinate system. The first set of points, `pc3d`, contains two points that cane be safely projected into the image plane while the second set `pc3d_z0` contains one invalid point (because it's z coorinate is zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = Intrinsics.from_test_model()\n",
    "pc3d =    np.array([[0.5, 0.6, 4.], [0.5, 0.6, 2.0], [0.1, 0.3, 1.5], [0.7, 0.3, 1.0]])    # 4 valid points form projection\n",
    "pc3d_z0 = np.array([[0.5, 0.6, 0.], [0.5, 0.6, 2.0], [0.1, 0.3, 0,], [0.7, 0.3, 1.0]])    # 2 valid points in the set of 4 points\n",
    "print(f'Using camera model: {ci.camera_model_name}, point sets with 4 3D points of shape: {pc3d.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi__c2i, disparity__c2i, is_valid__c2i = ci.camera2image_points(pc3d)\n",
    "print(f'pc3d: {pi__c2i.shape[0]} points in image plane, disparty: {disparity__c2i.squeeze().tolist()},  is_valid: {is_valid__c2i}')\n",
    "\n",
    "pi_z0__c2i, disparity_z0__c2i, is_valid_z0__c2i = ci.camera2image_points(pc3d_z0)\n",
    "pi_z0__c2i_good = pi_z0__c2i[is_valid_z0__c2i,:]\n",
    "disparity_z0__c2i_good = disparity_z0__c2i[is_valid_z0__c2i,:]\n",
    "\n",
    "print(f'pc3d_z0: {pi_z0__c2i_good.shape[0]} good point in image plane, disparty: {disparity_z0__c2i_good.squeeze().tolist()}, is_valid: {is_valid_z0__c2i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The projection is divided into three separate operations: `project_points`, `distort_points` and `to_image_points`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `project_points`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Intrinsics.project_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projections are covered in [Szeliski](http://szeliski.org/Book/), sec 2.1.4 in great detail. Currently we only support the perspective projection:\n",
    "$$\n",
    "\\tilde{P}_c = \\begin{pmatrix} x_c \\\\ y_c \\\\ z_c \\\\1  \\end{pmatrix}  \\Rightarrow \\tilde{p}_c = \\begin{pmatrix} x_c/z_c \\\\ y_c/z_c \\\\ 1  \\end{pmatrix}\n",
    "$$\n",
    "The method `project_points` produces, in addition to the 2D points also the value of the `diaparity` (namely the inverse depth $1/z$) and the last component returned is a boolean vector `valid` for indexing the cases where the transformation was valid, in particular when $z$ was not too close to zero.\n",
    "\n",
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_undistorted, disparity, is_valid = ci.project_points(pc3d)\n",
    "print(f'Points in camera plane of shape {p2_undistorted.shape}, disparty: {disparity.squeeze().tolist()}, is_valid: {is_valid}')\n",
    "\n",
    "assert np.linalg.norm(disparity-disparity__c2i) < 1e-5, f'Assetrion failed disparity from project_points [{disparity}] not equal to disparity from camera2image_points [{disparity__c2i}]'\n",
    "\n",
    "p2d_z0, disparity_z0, is_valid_z0 = ci.project_points(pc3d_z0)\n",
    "pi_z0__good = p2d_z0[is_valid_z0,:]\n",
    "disparity_z0_good = disparity_z0[is_valid_z0,:]\n",
    "assert np.linalg.norm(disparity_z0__c2i_good-disparity_z0_good) < 1e-5, f'Assetrion failed: valid disparity produced by \"project_points\" [{disparity_z0_good}] not equal to valid disparity produced by camera2image_points [{disparity_z0__c2i_good}]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `distort_points` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Intrinsics.distort_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the distortion model as defined by the camera model: \n",
    "$$\n",
    " \\tilde{p}_c = \\begin{pmatrix} x_c/z_c \\\\ y_c/z_c \\\\ 1  \\end{pmatrix} \\Rightarrow p_d = \\begin{pmatrix} x_d \\\\ y_d   \\end{pmatrix}  = \\tt{distorion\\_function}(p_c)\n",
    "$$\n",
    "The camera models `PINHOLE` and `SIMPLE_PINHOLE` do not have distortions and then the distortion function reduces to the identity function. In all OpenCv compatible models we use the distortion function as described in [Understanding Lens Distortion](https://learnopencv.com/understanding-lens-distortion/)\n",
    "\n",
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_distorted = ci.distort_points(p2_undistorted)\n",
    "print(f'Points undistorted in camera plane of shape: {p2_undistorted.shape}, first point: {p2_undistorted[0]}')\n",
    "print(f'Points distorted in camera plane of shape  : {p2_distorted.shape}, first_point: {p2_distorted[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always possible to join the `project_points` and `distort_points` into a single `project_and_distort_points` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Intrinsics.project_and_distort_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For OpenCv camera model, exceept `OPENCV5`, that use the either the function [projectPoints](https://docs.opencv.org/4.5.4/d9/d0c/group__calib3d.html#ga1019495a2c8d1743ed5cc23fa0daff8c) or the function [fisheye.projectPoints](https://docs.opencv.org/4.5.4/db/d58/group__calib3d__fisheye.html#gab1ad1dc30c42ee1a50ce570019baf2c4) there is no way of calling to `project_points` and `distort_points` separatly so the only option is calling to `project_and_distort_points`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_cv = Intrinsics.from_test_model(as_full_opencv=True)   # construct full OpenCv caera model\n",
    "print(f'camera model: {ci.camera_model_name}')\n",
    "p2_distorted_cv, disparity_cv, is_valid_cv = ci_cv.project_and_distort_points(pc3d)\n",
    "print(f'Points in camera plane (project_and_distort_points): {p2_distorted_cv.shape}, disparty: {disparity_cv.squeeze().tolist()}, is_valid: {is_valid_cv}')\n",
    "\n",
    "p2d_z0_cv, disparity_z0_cv, is_valid_z0_cv = ci_cv.project_and_distort_points(pc3d_z0)\n",
    "print(f'Good points in camera plane (project_and_distort_points): {p2d_z0_cv[is_valid_z0_cv].shape}, disparty: {disparity_z0_cv[is_valid_z0_cv].squeeze().tolist()}, is_valid: {is_valid_z0_cv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For non OpenCv camera models the result of calling to `project_and_distort_points` to first calling to `project_points` and then calling to `distort_points`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_distorted_1, disparity_1, valid_1 = ci.project_and_distort_points(pc3d)\n",
    "\n",
    "err_p2u_project_and_distort_points = np.linalg.norm(p2_distorted-p2_distorted_1)\n",
    "assert  err_p2u_project_and_distort_points < 1e-5, f'Assertion error. Error in results of \"project_and_distort_points\" vs  \"project_points\" and \"distort_points\" is too large: {err_p2u_project_and_distort_points}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `to_image_points`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Intrinsics.to_image_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In homogous coordinates the transformation is:\n",
    "$$\n",
    " \\begin{pmatrix} u \\\\ v  \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} f_x & 0 & c_x   \\\\  0 & f_y & c_y  \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} x_d \\\\ y_d  \\\\ 1 \\end{pmatrix} = K \\begin{pmatrix} x_d \\\\ y_d  \\\\ 1 \\end{pmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_image = ci.to_image_points(p2_distorted)\n",
    "print(f'Shape of pixels points: {p_image.shape}, first point: {p_image[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unproject  points\n",
    "\n",
    "The unprojection functions is about transforming back pixels into 3D points which is in general impossible, unless we know the `disparity`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we transform image pixels into tha camera plane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Intrinsics.to_camera_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Namely \n",
    "$$\n",
    " \\begin{pmatrix} x_d \\\\ y_d  \\\\ 1 \\end{pmatrix}  = k^{-1} \\begin{pmatrix} u \\\\ v  \\\\ 1 \\end{pmatrix} \n",
    "$$\n",
    "where \n",
    "$$\n",
    "k^{-1} =  \\begin{pmatrix} 1/f_x & 0 & -c_x/f_x   \\\\  0 & 1/f_y & -c_y/f_y  \\\\ 0 & 0 & 1 \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_distorted_back_projected = ci.to_camera_points(p_image)\n",
    "\n",
    "err_distortion_backprojection_1 = np.linalg.norm(p2_distorted_back_projected-p2_distorted)\n",
    "assert err_distortion_backprojection_1 < 1e-5, f'Assertion failed error of unptojection to camera plane [{err_distortion_backprojection_1}] is too large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to undistort the points in the image plane. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Intrinsics.undistort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I most cases, this procedure involves solving a polynomial equation by Newton iterations. The procedure converges very fast, and we use the OpenCv conventions and restrict the number of iterations to 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_undistorted_back_projected = ci.undistort(p2_distorted_back_projected)\n",
    "\n",
    "err_undistortion_backprojection_1 = np.linalg.norm(p2_undistorted_back_projected-p2_undistorted)\n",
    "assert err_undistortion_backprojection_1 < 1e-5, f'Assertion failed error of unptojection to camera plane [{err_undistortion_backprojection_1}] is too large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we convert from the undistorted camera plane to the 3D camera coordinate system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests\n",
    "\n",
    "The data is taken from the [OpenCV calibration tutorial](https://docs.opencv.org/3.3.0/dc/dbb/tutorial_py_calibration.html) and was copied from [this directory](https://github.com/opencv/opencv/tree/master/samples/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "ci = Intrinsics.from_test_model()\n",
    "\n",
    "ci_cv = Intrinsics.from_test_model(as_full_opencv=True)   # same model as ci but defined as OPENCV modxel with last 3 distortion coeffs = 0\n",
    "print(f'full cv camera model: {ci_cv.camera_model_name}')\n",
    "\n",
    "print(f'Test camera of type  {ci.camera_model_name}')\n",
    "\n",
    "# twopoints\n",
    "points_camera = np.array(\n",
    "    [\n",
    "        [0.5, 0.5,1.],\n",
    "        [0.5,0.5,2.],\n",
    "        [0.5,0.5,1.4]\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# produce a OPENCV5 model that is not handled by OpenCv functions\n",
    "p2d_cv, d_cv, is_valid_cv = ci_cv.project_and_distort_points(points_camera)\n",
    "p2d, d, is_valid = ci.project_and_distort_points(points_camera)\n",
    "err_pts = np.linalg.norm(p2d_cv-p2d)\n",
    "err_d = np.linalg.norm(d_cv-d)\n",
    "assert err_pts < 1e-5, f'assersion failed comparing project_and_distort_points points to OpenCv [{err_pts}]'\n",
    "assert err_d < 1e-5, f'assersion failed comparing project_and_distort_points disparities to OpenCv [{err_d}]'\n",
    "\n",
    "# Test 1 : camera2image_points model to OpenCv computation\n",
    "pimage, disparity, valid = ci.camera2image_points(points_camera)\n",
    "\n",
    "no_rot = np.array([[0.0], [0.0], [0.0]])\n",
    "no_trans = np.array([[0.0], [0.0], [0.0]])\n",
    "pimage_cv, _ =  cv2.projectPoints(points_camera,                              # project to image\n",
    "                           no_rot,\n",
    "                           no_trans,\n",
    "                           ci.K_3,\n",
    "                           ci.distortions)\n",
    "pimage_cv = pimage_cv.squeeze(1)\n",
    "\n",
    "# compare mvgutils to output of OpenCv\n",
    "err_test_1 = np.linalg.norm(pimage_cv-pimage)\n",
    "assert err_test_1 < 1e-5,  f'assersion failed distance between and OpenCV is too large [{err_test_1}]'\n",
    "\n",
    "\n",
    "# Test 2 : transform from camera pixels to distgorted camera plane and then undistort\n",
    "pd = ci.to_camera_points(pimage)\n",
    "pu = ci.undistort(pd)\n",
    "\n",
    "ppp = np.expand_dims(pimage,1)\n",
    "cv_undistorted =  cv2.undistortPoints(ppp, ci.K_3, ci.distortions).squeeze()\n",
    "\n",
    "err_test_2 = np.linalg.norm(pu-cv_undistorted)\n",
    "assert err_test_2 < 1e-5, f'assersion failed distance between and OpenCV is too large [{err_test_2}]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_images():\n",
    "    root_dir = Path(os.getcwd())\n",
    "    if str(root_dir) not in sys.path:\n",
    "        sys.path.insert(0,str(root_dir))\n",
    "    else:\n",
    "        print('PATH O.K.')\n",
    "\n",
    "    img_dir = root_dir / 'data' \n",
    "    img_file = img_dir / 'left03.jpg'\n",
    "    img = cv2.imread(str(img_file))\n",
    "    h,  w = img.shape[:2]\n",
    "    print(w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mvgutils')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
