[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "mvgutils",
    "section": "",
    "text": "MVG utils > Set of utilities helping in setting and displaying multi view geometries\nThis file will become your README and also the index of your documentation. Inspired by the multiview geometry notebooks repo"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "mvgutils",
    "section": "Install",
    "text": "Install\nInstall using:\npip install mvgutils\nor:\nconda install -c fastai mvgutils"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "mvgutils",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2"
  },
  {
    "objectID": "plot3d.html",
    "href": "plot3d.html",
    "title": "plot3d",
    "section": "",
    "text": "Before any plotting command ,be sure to initialize the plot volume in which all geometries are expected to be embedded.\n\nsource\n\n\n\n init_3d_plot (xmin, xmax, ymin, ymax, zmin, zmax)\n\nInitializes a ipyvolume 3d plot. Returns a fig\n\nxmin = -2.0\nxmax = 2.0\nymin = -2.0\nymax = 2.0\nzmin = -2.0\nzmax = 2.0\nfig = init_3d_plot(xmin, xmax, ymin, ymax, zmin, zmax)\n# fig\nfig\n\n\nsource\n\n\n\n\n plot_planar_rect (plane3d:mvgutils.plane3d.Plane3d, size_v1=1.0,\n                   size_v2=1.0, limits=None, show_bbox:bool=False,\n                   show_normal:bool=False)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nplane3d\nPlane3d\n\n\n\n\nsize_v1\nfloat\n1.0\n\n\n\nsize_v2\nfloat\n1.0\n\n\n\nlimits\nNoneType\nNone\n\n\n\nshow_bbox\nbool\nFalse\nTrue if you wish to display plot limits\n\n\nshow_normal\nbool\nFalse\nTrue if you wish to display normal\n\n\n\n\ndef plot_axes(s=1.0):\n    p0 = np.array([0.0,0.0,0.0])\n    px = np.array([s,0.0,0.0])\n    py = np.array([0.0,s,0.0])\n    pz = np.array([0.0,0.0,s])\n\n    fig = init_3d_plot(-2.0, 2.0, -2.0, 2.0, -2.0, 2.0)\n\n    p_x = ipv.plot([p0[0], px[0]], [p0[1], px[1]],[p0[2], px[2]], color='red', size=3)\n\n    ipv.plot([p0[0], py[0]], [p0[1], py[1]],[p0[2], py[2]], color='green')\n    ipv.plot([p0[0], pz[0]], [p0[1], pz[1]],[p0[2], pz[2]], color='blue')\n\n\n    return ipv\n\nplot_axes().show()\n\nBuild the plane that passes thgrough points \\((0,0,0)\\), \\((0,1,0)\\) and \\((1,1,0)\\). This is the plane \\(z=0\\)\n\np0 = np.array([0.0,0.0,0.0])\np1 = np.array([0.0,1.0,0.0])\np2 = np.array([1.0,1.0,0.0])\nplane_3d = Plane3d.from_3_points(p0,p1,p2)\nipv = plot_planar_rect(plane_3d, show_bbox=True, show_normal=True)\nipv.show()\n\n\nfrom nbdev import nbdev_export\nnbdev_export()"
  },
  {
    "objectID": "intrinsics.html",
    "href": "intrinsics.html",
    "title": "Intrinsics",
    "section": "",
    "text": "The class Intrinsics models a pinhole camera with distortions. Useful books are:\n\nThe book Computer Vision: Algorithms and Applications, 2nd ed., Richard Szeliski, 2022 that can be freely downloaded.\nMultiple View Geometry in Computer Vision, 2nd ed., Hartley and Zisserman, , Cambridge University Press, 2004\nAn Invitation to 3-D Vision (pdf), Yi Ma, Jana Koˇseck´a, Stefano Soatto, Shankar Sastry, 2001\n\n\nsource\n\n\n\n from_homogeneous (points)\n\nRemove the homogeneous dimension of N-dimensional points. Args: points: torch.Tensor or numpy.ndarray with size (…, N+1). Returns: A torch.Tensor or numpy ndarray with size (…, N).\n\nsource\n\n\n\n\n to_homogeneous (points)\n\nConvert N-dimensional points to homogeneous coordinates. Args: points: torch.Tensor or numpy.ndarray with size (…, N). Returns: A torch.Tensor or numpy.ndarray with size (…, N+1).\n\nsource\n\n\n\n\n Intrinsics (camera_model_name:str, width:int, height:int, params:list)\n\nCamera intrinsic model\n\n\n\n\nType\nDetails\n\n\n\n\ncamera_model_name\nstr\nOne of the keys in SUPPORTED_CAMERA_MODELS\n\n\nwidth\nint\nwidth of the image in pixels\n\n\nheight\nint\nheight of the image in pixels\n\n\nparams\nlist\nparameters, in COLMAP conventions"
  },
  {
    "objectID": "intrinsics.html#supported-camera-models",
    "href": "intrinsics.html#supported-camera-models",
    "title": "Intrinsics",
    "section": "Supported camera models",
    "text": "Supported camera models\nThis is the list of all supported camera models. Each item includes tha name of the camera model, e.g. SIMPLE_RADIAL and list of expected parameters as handled by Intrinsics. All camera models of COLMAP are supported and some more, as needed.\n\nIntrinsics.supported_camera_models()\n\nList of supported camera models and their parameters\n_______________________________________________________\nSIMPLE_PINHOLE      : f, cx, cy\nPINHOLE             : fx, fy, cx, cy\nSIMPLE_RADIAL       : f, cx, cy, k\nRADIAL              : f, cx, cy, k1, k2\nOPENCV              : fx, fy, cx, cy, k1, k2, p1, p2\nOPENCV_FISHEYE      : fx, fy, cx, cy, k1, k2, k3, k4\nFULL_OPENCV         : fx, fy, cx, cy, k1, k2, p1, p2, k3, k4, k5, k6\nFOV                 : fx, fy, cx, cy, omega\nOPENCV5             : fx, fy, cx, cy, k1, k2, p1, p2, k3\nUNKNOWN             : []"
  },
  {
    "objectID": "intrinsics.html#construct-camera-model",
    "href": "intrinsics.html#construct-camera-model",
    "title": "Intrinsics",
    "section": "Construct camera model",
    "text": "Construct camera model\n\nInitialization\nCall to the constructor of the class with parameters such as\n\nc = Intrinsics(\n    camera_model_name='OPENCV5',\n    width=640,\n    height=320,\n    params=[400, 410.0, 320, 160,14,15,16,17,228]\n)\n\nc\n\nCamera: OPENCV5\n  w,h=(640, 320)\n  params: [400.0, 410.0, 320.0, 160.0, 14.0, 15.0, 16.0, 17.0, 228.0]\n  cx,cy= (320.0,160.0)\n  fx,fy= (400.0,410.0)\n  distortions: [ 14.  15.  16.  17. 228.]\n\n\n\nsource\n\n\nIntrinsics.from_opencv_model\n\n Intrinsics.from_opencv_model (K:numpy.ndarray, distortions:numpy.ndarray,\n                               width:int, height:int)\n\nContructing camera intrinsics model from opencv compatible data\n\n\n\n\nType\nDetails\n\n\n\n\nK\nndarray\n3x3 camera matrix\n\n\ndistortions\nndarray\ndistortion array as produced by OpenCv\n\n\nwidth\nint\nCamera width in pixels\n\n\nheight\nint\nCamera height in pixels\n\n\nReturns\nIntrinsics\n\n\n\n\n\nsource\n\n\nIntrinsics.from_opencv_fisheye_model\n\n Intrinsics.from_opencv_fisheye_model (K:numpy.ndarray,\n                                       distortions:numpy.ndarray,\n                                       width:int, height:int)\n\nContructing camera intrinsics model from data compatible with opencv fisheye model\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nK\nndarray\n3x3 camera matrix\n\n\ndistortions\nndarray\ndistortion array for OpenCv fisheye model, should consist of 4 distrortion parameters\n\n\nwidth\nint\nCamera width in pixels\n\n\nheight\nint\nCamera height in pixels\n\n\nReturns\nIntrinsics\n\n\n\n\n\nsource\n\n\nIntrinsics.from_pinhole_model\n\n Intrinsics.from_pinhole_model (fx:float, fy:float, cx:float, cy:float,\n                                width:int, height:int)\n\nContructing camera intrinsics model from opencv compatible data\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nfx\nfloat\nFocal length (x) in pixels\n\n\nfy\nfloat\nFocal length (y) in pixels. fy might be equal to fx (SIMPLE_PINHOLE model) or different (PINHOLE model)\n\n\ncx\nfloat\nCamera center (x) in pixels\n\n\ncy\nfloat\nCamera center (y) in pixels\n\n\nwidth\nint\nImage width in pixels\n\n\nheight\nint\nImage height in pixels\n\n\nReturns\nIntrinsics\n\n\n\n\nAs an example, consider the construction from an OpenCv model with 5 parameters:\n\nwidth = 1280\nheight = 720\nfx = 600\nfy = 600\ncx = 1280 /2\ncy = 720 /2\nK = np.array(\n    [\n        [fx, 0.0, cx],\n        [0.0, fy, cy],\n        [0.0,0.0,1.0]\n    ]\n)\n\n\ndistortions = [-1.51960304e-01,  5.60700273e-01, -1.28234990e-02,  1.41775450e-03, 5.23404322e+00]\nIntrinsics.from_opencv_model(K,distortions,width, height)\n\nCamera: OPENCV5\n  w,h=(1280, 720)\n  params: [600.0, 600.0, 640.0, 360.0, -0.151960304, 0.560700273, -0.012823499, 0.0014177545, 5.23404322]\n  cx,cy= (640.0,360.0)\n  fx,fy= (600.0,600.0)\n  distortions: [-1.51960304e-01  5.60700273e-01 -1.28234990e-02  1.41775450e-03\n  5.23404322e+00]\n\n\n\nsource\n\n\nIntrinsics.from_test_model\n\n Intrinsics.from_test_model (as_full_opencv=False)\n\nContructing camera intrinsics model from opencv calibration tutorial\nThe test model is taken form the OpenCV calibration tutorial and the images used for calibrating the test model are given in this directory\n\nIntrinsics.from_test_model()\n\nCamera: OPENCV5\n  w,h=(640, 480)\n  params: [535.915733961632, 535.915733961632, 342.28315473308373, 235.57082909788173, -0.2663726090966068, -0.03858889892230465, 0.0017831947042852964, -0.0002812210044111547, 0.23839153080878486]\n  cx,cy= (342.28315473308373,235.57082909788173)\n  fx,fy= (535.915733961632,535.915733961632)\n  distortions: [-0.26637261 -0.0385889   0.00178319 -0.00028122  0.23839153]"
  },
  {
    "objectID": "intrinsics.html#access-functions",
    "href": "intrinsics.html#access-functions",
    "title": "Intrinsics",
    "section": "Access functions",
    "text": "Access functions\n\nprint(f'Camera : {c.camera_model_name}, fx={c.fx}, fy={c.fy}, cx={c.cx}, cy={c.cy}, distortions={c.distortions}')\nprint(f'Camera width: {c.w}, heigth: {c.h}')\n\nCamera : OPENCV5, fx=400.0, fy=410.0, cx=320.0, cy=160.0, distortions=[ 14.  15.  16.  17. 228.]\nCamera width: 640, heigth: 320\n\n\n\nsource\n\nIntrinsics.K\n\n Intrinsics.K ()\n\nReturn the 4x4 camera matrix in homogenous coordinates\n\nsource\n\n\nIntrinsics.K_inv\n\n Intrinsics.K_inv ()\n\nReturn the 4x4 inverse of camera matrix in homogenous coordinates\n\nsource\n\n\nIntrinsics.K_3\n\n Intrinsics.K_3 ()\n\nReturn the 3x3 camera matrix in npn homogenous coordinates\n\nsource\n\n\nIntrinsics.K_3_inv\n\n Intrinsics.K_3_inv ()\n\nReturn the 3x3 inverse of the camera matrix in npn homogenous coordinates\n\nprint(f'Homogenous camera matrix: \\n {c.K}, {c.K.dtype}')\nprint(f'Non homogenous camera matrix: \\n {c.K_3}')\n\nHomogenous camera matrix: \n [[400.   0. 320.   0.]\n [  0. 410. 160.   0.]\n [  0.   0.   1.   0.]\n [  0.   0.   0.   1.]], float64\nNon homogenous camera matrix: \n [[400.   0. 320.]\n [  0. 410. 160.]\n [  0.   0.   1.]]\n\n\n\nsource\n\n\nIntrinsics.distortions\n\n Intrinsics.distortions ()\n\nReturns 1D distortion array\n\nprint(f'Distortions: {c.distortions}, {c.distortions.dtype}')\n\nDistortions: [ 14.  15.  16.  17. 228.], float64\n\n\n\nsource\n\n\nIntrinsics.params\n\n Intrinsics.params ()\n\nGet list of parametes as expected in the consrtructor for the given camera model\n\nprint(f'Parameters of camera model {c.camera_model_name}: {c.params}')\n\nParameters of camera model OPENCV5: [400.0, 410.0, 320.0, 160.0, 14.0, 15.0, 16.0, 17.0, 228.0]\n\n\n\nsource\n\n\nIntrinsics.get_fov\n\n Intrinsics.get_fov ()\n\nGet horizontal and vertical field of view of the canera, in degrees\n\nIntrinsics.from_test_model().get_fov()\n\n{'fovx': 61.683594005974356, 'fovy': 48.248686484809355}"
  },
  {
    "objectID": "intrinsics.html#transformations",
    "href": "intrinsics.html#transformations",
    "title": "Intrinsics",
    "section": "Transformations",
    "text": "Transformations\nTransformations such as scale or crop effect also the camera model. We need to update the camera model to be cosistent with the scaled/cropped image.\n\nbase_camera = Intrinsics.from_test_model()\nbase_camera\n\nCamera: OPENCV5\n  w,h=(640, 480)\n  params: [535.915733961632, 535.915733961632, 342.28315473308373, 235.57082909788173, -0.2663726090966068, -0.03858889892230465, 0.0017831947042852964, -0.0002812210044111547, 0.23839153080878486]\n  cx,cy= (342.28315473308373,235.57082909788173)\n  fx,fy= (535.915733961632,535.915733961632)\n  distortions: [-0.26637261 -0.0385889   0.00178319 -0.00028122  0.23839153]\n\n\n\nsource\n\nIntrinsics.scale\n\n Intrinsics.scale (scale_by:Tuple)\n\nUpdate Intrinsicss after scaling an image\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nscale_by\nTuple\nSacle factors as (scale_width, scale_height)\n\n\nReturns\nIntrinsics\nIntrinsics for camera producing the scaled image\n\n\n\n\nbase_camera.scale((0.5,0.5))\n\nCamera: OPENCV5\n  w,h=(320, 240)\n  params: [267.957866980816, 267.957866980816, 171.14157736654187, 117.78541454894086, -0.2663726090966068, -0.03858889892230465, 0.0017831947042852964, -0.0002812210044111547, 0.23839153080878486]\n  cx,cy= (171.14157736654187,117.78541454894086)\n  fx,fy= (267.957866980816,267.957866980816)\n  distortions: [-0.26637261 -0.0385889   0.00178319 -0.00028122  0.23839153]\n\n\n\nsource\n\n\nIntrinsics.resize\n\n Intrinsics.resize (new_size:Tuple)\n\nUpdate Intrinsicss after resizing an image\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nnew_size\nTuple\nNew size as (new_width, new_height)\n\n\nReturns\nIntrinsics\nIntrinsics for the camera producing the resized image\n\n\n\n\nbase_camera.resize((240,240))\n\nCamera: OPENCV5\n  w,h=(240, 240)\n  params: [200.968400235612, 267.957866980816, 128.3561830249064, 117.78541454894086, -0.2663726090966068, -0.03858889892230465, 0.0017831947042852964, -0.0002812210044111547, 0.23839153080878486]\n  cx,cy= (128.3561830249064,117.78541454894086)\n  fx,fy= (200.968400235612,267.957866980816)\n  distortions: [-0.26637261 -0.0385889   0.00178319 -0.00028122  0.23839153]\n\n\n\nsource\n\n\nIntrinsics.crop\n\n Intrinsics.crop (top_left:Tuple[float], crop_size:Tuple[int])\n\nUpdate Intrinsicss after cropping an image\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ntop_left\nTuple\nTop left pixel of cropped image as (x,y)\n\n\ncrop_size\nTuple\nSize of cropped bbox (size_x, size_y)\n\n\nReturns\nIntrinsics\nIntrinsics for the camera producing the cropped image\n\n\n\n\nbase_camera.crop(top_left=(100,100), crop_size=(200,200))\n\nCamera: OPENCV5\n  w,h=(200, 200)\n  params: [535.915733961632, 535.915733961632, 242.28315473308373, 135.57082909788173, -0.2663726090966068, -0.03858889892230465, 0.0017831947042852964, -0.0002812210044111547, 0.23839153080878486]\n  cx,cy= (242.28315473308373,135.57082909788173)\n  fx,fy= (535.915733961632,535.915733961632)\n  distortions: [-0.26637261 -0.0385889   0.00178319 -0.00028122  0.23839153]"
  },
  {
    "objectID": "intrinsics.html#image-undistortion",
    "href": "intrinsics.html#image-undistortion",
    "title": "Intrinsics",
    "section": "Image undistortion",
    "text": "Image undistortion\n\nsource\n\nIntrinsics.get_undistort_camera\n\n Intrinsics.get_undistort_camera (alpha:float)\n\nUpdate Intrinsicss for camera producing the undistorted image/points\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nalpha\nfloat\nA number between 0 (all pixels in the undistorted image are valid) and 1 (all source images are retained but there are some black pixels)\n\n\nReturns\nIntrinsics\nA PINHOLE camera model that corresponds to the undistorted image\n\n\n\n\nbase_camera = Intrinsics.from_test_model().scale((0.5,0.5))\nprint(base_camera)\n\nprint('Comparing impelementation of get_undistort_camera to OpenCv getOptimalNewCameraMatrix for different values of alpha')\nmtx = base_camera.K_3\nerrors_K = []\nfor alpha in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n    new_matrix_cv, roi = cv2.getOptimalNewCameraMatrix(\n        base_camera.K_3,\n        base_camera.distortions,\n        (base_camera.w,base_camera.h),\n        alpha=alpha\n    )\n    # print(roi)\n\n    new_camera = base_camera.get_undistort_camera(alpha=alpha)\n\n    err_new_matrix = np.linalg.norm(new_camera.K_3-new_matrix_cv)\n    errors_K.append(err_new_matrix)\n\nassert np.any(np.array(errors_K) < 0.002), f'Large errors between OpenCV and \"get_undistort_camera\": [{errors_K}]'\n\nCamera: OPENCV5\n  w,h=(320, 240)\n  params: [267.957866980816, 267.957866980816, 171.14157736654187, 117.78541454894086, -0.2663726090966068, -0.03858889892230465, 0.0017831947042852964, -0.0002812210044111547, 0.23839153080878486]\n  cx,cy= (171.14157736654187,117.78541454894086)\n  fx,fy= (267.957866980816,267.957866980816)\n  distortions: [-0.26637261 -0.0385889   0.00178319 -0.00028122  0.23839153]\n\nComparing impelementation of get_undistort_camera to OpenCv getOptimalNewCameraMatrix for different values of alpha\n\n\n\nsource\n\n\nIntrinsics.init_undistort_rectify_map\n\n Intrinsics.init_undistort_rectify_map (alpha)\n\nReturn parameters needed for image undistortion plut the PINHOLE camera model of the undistorted image\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nalpha\n\nA number between 0 (all pixels in the undistorted image are valid) and 1 (all source images are retained but there are some black pixels)\n\n\nReturns\nEasyDict\ndict with entries: “pinhole_camera”, “mapx”, “mapy” consisting of all infor needed to undistort an image\n\n\n\n\nfor alpha in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n    r = base_camera.init_undistort_rectify_map(alpha=1.0)\n\n    opencv_mapx, opencv_mapy = cv2.initUndistortRectifyMap(\n        base_camera.K_3, \n        base_camera.distortions,\n        None,\n        r.pinhole_camera.K_3,\n        (r.pinhole_camera.w,r.pinhole_camera.h),\n        cv2.CV_32FC1\n    )\n\n    ex = np.linalg.norm(r.mapx-opencv_mapx)\n    ey = np.linalg.norm(r.mapy-opencv_mapy)\n    assert ex < 0.01, f'Assertion error (alpha={alpha}): Errors: mapx_opencv-mapx={ex}'\n    assert ey < 0.01, f'Assertion error (alpha={alpha}): Errors: mapy_opencv-mapy={ey}'\n\nWith the results of init_undistort_rectify_map we can now undistort images. The undistorted image correspond to the PINHOLE camera model.\n\nsource\n\n\nIntrinsics.undistort_image\n\n Intrinsics.undistort_image (img:numpy.ndarray,\n                             undistorted_info:easydict.EasyDict)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nimg\nndarray\nInput image\n\n\nundistorted_info\nEasyDict\nThe output from ‘init_undistort_rectify_map’\n\n\nReturns\nndarray\nundistorted image\n\n\n\nIn the following examples we will undistort an images, given a calibrated camera. The camera parameters and the images taken from the data directory used by the OpenCV calibration tutorial.\n\nci = Intrinsics.from_test_model()\nprint(f'Distorted image: camera-model={ci.camera_model_name}: fx={ci.fx}, fy={ci.fy}, cx={ci.cx}, cy={ci.cy}')\n\nroot_dir = Path(os.getcwd())\nif str(root_dir) not in sys.path:\n    sys.path.insert(0,str(root_dir))\n\nimg_dir = root_dir / 'data' \nimg_file = img_dir / 'left03.jpg'\ncv_img = cv2.imread(str(img_file))\n\ncv_img = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\npil_img = Image.fromarray(cv_img)\ndisplay(pil_img)\n\nDistorted image: camera-model=OPENCV5: fx=535.915733961632, fy=535.915733961632, cx=342.28315473308373, cy=235.57082909788173\n\n\n\n\n\nWith alpha=1.0 all original pixels of the distorted image are kept also in the undistorted version. The drawback is that we now many black pixels in the perimeter of the image.\n\nalpha = 1.0\nr = ci.init_undistort_rectify_map(alpha=alpha)\ncp = r.pinhole_camera\nprint(f'Undistrted image (alpha={alpha}): camera-model={cp.camera_model_name}: fx={cp.fx}, fy={cp.fy}, cx={cp.cx}, cy={cp.cy}')\n\nimg_undistorted = Intrinsics.undistort_image(cv_img, r)\nim_pil_u = Image.fromarray(img_undistorted)\ndisplay(im_pil_u)\n\nUndistrted image (alpha=1.0): camera-model=PINHOLE: fx=467.88845379768406, fy=468.28742729330503, cx=341.4258283195987, cy=236.2097112614839\n\n\n\n\n\nWith alpha=0.0 value, we have no black pixels but some pixels of the original image are lost.\n\nalpha = 0.0\nr = ci.init_undistort_rectify_map(alpha=alpha)\ncp = r.pinhole_camera\nprint(f'Undistrted image (alpha={alpha}): camera-model={cp.camera_model_name}: fx={cp.fx}, fy={cp.fy}, cx={cp.cx}, cy={cp.cy}')\n\nimg_undistorted = Intrinsics.undistort_image(cv_img, r)\nim_pil_u = Image.fromarray(img_undistorted)\ndisplay(im_pil_u)\n\nUndistrted image (alpha=0.0): camera-model=PINHOLE: fx=478.9090531962673, fy=502.669315116053, cx=345.568809503914, cy=235.2218688743195\n\n\n\n\n\nIt is, of course, posible to change alpha between 0 and 1 to control the tradeoff between number of black pixels and number of pixels in the distorted image that are lost.\n\nalpha = 0.4\nr = ci.init_undistort_rectify_map(alpha=alpha)\ncp = r.pinhole_camera\nprint(f'Undistrted image (alpha={alpha}): camera-model={cp.camera_model_name}: fx={cp.fx}, fy={cp.fy}, cx={cp.cx}, cy={cp.cy}')\n\nimg_undistorted = Intrinsics.undistort_image(cv_img, r)\nim_pil_u = Image.fromarray(img_undistorted)\ndisplay(im_pil_u)\n\nUndistrted image (alpha=0.4): camera-model=PINHOLE: fx=474.50081343683405, fy=488.91655998695376, cx=343.91161703018787, cy=235.61700582918527"
  },
  {
    "objectID": "intrinsics.html#project-and-unproject-points",
    "href": "intrinsics.html#project-and-unproject-points",
    "title": "Intrinsics",
    "section": "Project and unproject points",
    "text": "Project and unproject points\nPoints are represented in homogenous coordinates or in regular Eucledian coordinates. We will denote points in hompogenous coordinates with a tilde so a 3D point \\(P\\) in homogenous coordinates will be denoted by \\(\\tilde{P}\\). IN the same manner, 2D points will be written in small letters, such as \\(\\tilde{p}\\) in 2D homogenous coordinates and \\(p\\) in 2D Eucledian space.\n\nProject points\nThe function\n\nsource\n\n\nIntrinsics.camera2image_points\n\n Intrinsics.camera2image_points (pc3d:numpy.ndarray)\n\nProject 3D points in the camera reference coordinate system into image coordinates\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\npc3d\nndarray\n3D points in camera frame system with shape (N,3)\n\n\nReturns\nTuple\nA 2D point in the camera plane with shape (N,2), disparities with shape (N,1) and boolean valid mask with shape (N,)\n\n\n\nIn homegenous coordinates we have \\[\n\\tilde{p}_c = \\begin{pmatrix} x_c \\\\ y_c \\\\ z_c \\\\1  \\end{pmatrix}  \\Rightarrow \\tilde{p}_u = \\begin{pmatrix} u \\\\ v \\\\ \\tt{d}  \\end{pmatrix}\n\\] where \\(\\tilde{p}_c\\) is a 3D point in the camera coordinate system, \\(\\tilde{p}_u\\) consists of the pixel cooridates of that point, d is the disparity.\nThe function expects regular collection of 3D points as an array of shape (N,3) and returns:\n\n2D points in image plane, array of shape (N,2)\ndisparitiers (inverse depth), array of shape (N,2)\nA valid boolean vector for indexing the valid points. 3D points for which \\(z\\) is too close to zero are invalid\n\nWe consider two sets of 3D points in the camera coordinate system. The first set of points, pc3d, contains four points that can be safely projected into the image plane while the second set pc3d_z0 contains two invalid points, with \\(z=0\\).\n\nci = Intrinsics.from_test_model()\npc3d =    np.array([[0.5, 0.6, 4.], [0.5, 0.6, 2.0], [0.1, 0.3, 1.5], [0.7, 0.3, 1.0]])    # 4 valid points form projection\npc3d_z0 = np.array([[0.5, 0.6, 0.], [0.5, 0.6, 2.0], [0.1, 0.3, 0,], [0.7, 0.3, 1.0]])    # 2 valid points in the set of 4 points\nprint(f'Using camera model: {ci.camera_model_name}, point sets with 4 3D points of shape: {pc3d.shape}')\n\nUsing camera model: OPENCV5, point sets with 4 3D points of shape: (4, 3)\n\n\n\npi__c2i, disparity__c2i, is_valid__c2i = ci.camera2image_points(pc3d)\nprint(f'pc3d: {pi__c2i.shape[0]} points in image plane, disparty: {disparity__c2i.squeeze().tolist()},  is_valid: {is_valid__c2i}')\n\npi_z0__c2i, disparity_z0__c2i, is_valid_z0__c2i = ci.camera2image_points(pc3d_z0)\npi_z0__c2i_good = pi_z0__c2i[is_valid_z0__c2i,:]\ndisparity_z0__c2i_good = disparity_z0__c2i[is_valid_z0__c2i,:]\n\nprint(f'pc3d_z0: {pi_z0__c2i_good.shape[0]} good point in image plane, disparty: {disparity_z0__c2i_good.squeeze().tolist()}, is_valid: {is_valid_z0__c2i}')\n\npc3d: 4 points in image plane, disparty: [0.25, 0.5, 0.6666666666666666, 1.0],  is_valid: [ True  True  True  True]\npc3d_z0: 2 good point in image plane, disparty: [0.5, 1.0], is_valid: [False  True False  True]\n\n\nThe projection is divided into three separate operations: project_points, distort_points and to_image_points:\nThe function project_points\n\nsource\n\n\nIntrinsics.project_points\n\n Intrinsics.project_points (pc3d:numpy.ndarray,\n                            projection_type:str='perspective')\n\nProject 3D points in camera frame to 2D points in the camera plane\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npc3d\nndarray\n\n3D points in camera frame, with shape (N,3)\n\n\nprojection_type\nstr\nperspective\nProjection type\n\n\nReturns\nTuple\n\nA 2D point in the camera plane with shape (N,2), disparities with shape (N,1) and boolean valid mask with shape (N,)\n\n\n\nProjections are covered in Szeliski, sec 2.1.4 in great detail. Currently we only support the perspective projection: \\[\n\\tilde{P}_c = \\begin{pmatrix} x_c \\\\ y_c \\\\ z_c \\\\1  \\end{pmatrix}  \\Rightarrow \\tilde{p}_c = \\begin{pmatrix} x_c/z_c \\\\ y_c/z_c \\\\ 1  \\end{pmatrix}\n\\] The method project_points produces, in addition to the 2D points also the value of the diaparity (namely the inverse depth \\(1/z\\)) and the last component returned is a boolean vector valid for indexing the cases where the transformation was valid, in particular when \\(z\\) was not too close to zero.\nExample\n\np2_undistorted, disparity, is_valid = ci.project_points(pc3d)\nprint(f'Points in camera plane of shape {p2_undistorted.shape}, disparty: {disparity.squeeze().tolist()}, is_valid: {is_valid}')\n\nassert np.linalg.norm(disparity-disparity__c2i) < 1e-5, f'Assetrion failed disparity from project_points [{disparity}] not equal to disparity from camera2image_points [{disparity__c2i}]'\n\np2d_z0, disparity_z0, is_valid_z0 = ci.project_points(pc3d_z0)\npi_z0__good = p2d_z0[is_valid_z0,:]\ndisparity_z0_good = disparity_z0[is_valid_z0,:]\nassert np.linalg.norm(disparity_z0__c2i_good-disparity_z0_good) < 1e-5, f'Assetrion failed: valid disparity produced by \"project_points\" [{disparity_z0_good}] not equal to valid disparity produced by camera2image_points [{disparity_z0__c2i_good}]'\n\nPoints in camera plane of shape (4, 2), disparty: [0.25, 0.5, 0.6666666666666666, 1.0], is_valid: [ True  True  True  True]\n\n\nThe distort_points function\n\nsource\n\n\nIntrinsics.distort_points\n\n Intrinsics.distort_points (p_cam_undistorted:numpy.ndarray)\n\nDistort points in the camera plane\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\np_cam_undistorted\nndarray\n2D Undistorted point in the camera plane with shape (N,2)\n\n\nReturns\nndarray\n2D distorted point in the camera plane with shape (N,2)\n\n\n\nusing the distortion model as defined by the camera model: \\[\n\\tilde{p}_c = \\begin{pmatrix} x_c/z_c \\\\ y_c/z_c \\\\ 1  \\end{pmatrix} \\Rightarrow p_d = \\begin{pmatrix} x_d \\\\ y_d   \\end{pmatrix}  = \\tt{distorion\\_function}(p_c)\n\\] The camera models PINHOLE and SIMPLE_PINHOLE do not have distortions and then the distortion function reduces to the identity function. In all OpenCv compatible models we use the distortion function as described in Understanding Lens Distortion\nExample\n\np2_distorted = ci.distort_points(p2_undistorted)\nprint(f'Points undistorted in camera plane of shape: {p2_undistorted.shape}, first point: {p2_undistorted[0]}')\nprint(f'Points distorted in camera plane of shape  : {p2_distorted.shape}, first_point: {p2_distorted[0]}')\n\nPoints undistorted in camera plane of shape: (4, 2), first point: [0.125 0.15 ]\nPoints distorted in camera plane of shape  : (4, 2), first_point: [0.12377257 0.14860793]\n\n\nIt is always possible to join the project_points and distort_points into a single project_and_distort_points function.\n\nsource\n\n\nIntrinsics.project_and_distort_points\n\n Intrinsics.project_and_distort_points (pc3d:numpy.ndarray)\n\nProject 3D points in the camera reference coordinate system into 2D distorted points in the camera frame\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\npc3d\nndarray\n3D points in camera frame system with shape (N,3)\n\n\nReturns\nTuple\nA 2D point in the camera plane with shape (N,2), disparities with shape (N,1) and boolean valid mask with shape (N,)\n\n\n\nFor OpenCv camera model, exceept OPENCV5, that use the either the function projectPoints or the function fisheye.projectPoints there is no way of calling to project_points and distort_points separatly so the only option is calling to project_and_distort_points\n\nci_cv = Intrinsics.from_test_model(as_full_opencv=True)   # construct full OpenCv caera model\nprint(f'camera model: {ci.camera_model_name}')\np2_distorted_cv, disparity_cv, is_valid_cv = ci_cv.project_and_distort_points(pc3d)\nprint(f'Points in camera plane (project_and_distort_points): {p2_distorted_cv.shape}, disparty: {disparity_cv.squeeze().tolist()}, is_valid: {is_valid_cv}')\n\np2d_z0_cv, disparity_z0_cv, is_valid_z0_cv = ci_cv.project_and_distort_points(pc3d_z0)\nprint(f'Good points in camera plane (project_and_distort_points): {p2d_z0_cv[is_valid_z0_cv].shape}, disparty: {disparity_z0_cv[is_valid_z0_cv].squeeze().tolist()}, is_valid: {is_valid_z0_cv}')\n\ncamera model: OPENCV5\nPoints in camera plane (project_and_distort_points): (4, 2), disparty: [0.25, 0.5, 0.6666666666666666, 1.0], is_valid: [ True  True  True  True]\nGood points in camera plane (project_and_distort_points): (2, 2), disparty: [0.5, 1.0], is_valid: [False  True False  True]\n\n\nFor non OpenCv camera models the result of calling to project_and_distort_points to first calling to project_points and then calling to distort_points:\n\np2_distorted_1, disparity_1, valid_1 = ci.project_and_distort_points(pc3d)\n\nerr_p2u_project_and_distort_points = np.linalg.norm(p2_distorted-p2_distorted_1)\nassert  err_p2u_project_and_distort_points < 1e-5, f'Assertion error. Error in results of \"project_and_distort_points\" vs  \"project_points\" and \"distort_points\" is too large: {err_p2u_project_and_distort_points}'\n\nThe function to_image_points\n\nsource\n\n\nIntrinsics.to_image_points\n\n Intrinsics.to_image_points (pc_distorted:numpy.ndarray)\n\nTransform points from the camera plane to the image plane, using the camera matrix K\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\npc_distorted\nndarray\n2D points in the camera plane with shape (N,2)\n\n\nReturns\nndarray\n2D points in the image plane with shape (N,2)\n\n\n\nIn homogous coordinates the transformation is: \\[\n\\begin{pmatrix} u \\\\ v  \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} f_x & 0 & c_x   \\\\  0 & f_y & c_y  \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} x_d \\\\ y_d  \\\\ 1 \\end{pmatrix} = K \\begin{pmatrix} x_d \\\\ y_d  \\\\ 1 \\end{pmatrix}\n\\]\n\np_image = ci.to_image_points(p2_distorted)\nprint(f'Shape of pixels points: {p_image.shape}, first point: {p_image[0]}')\n\nShape of pixels points: (4, 2), first point: [408.61482149 315.21215808]\n\n\n\nUnproject points\nThe unprojection functions is about transforming back pixels into 3D points which is in general impossible, unless we know the disparity\nFirst we transform image pixels into tha camera plane:\n\nsource\n\n\n\nIntrinsics.to_camera_points\n\n Intrinsics.to_camera_points (pu:numpy.ndarray)\n\nTransform pixel image coordinates into the distorted camera plane\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\npu\nndarray\npoints in the image plane, shape is (N,2)\n\n\nReturns\nndarray\npoints in distorted camera plane, shape (N,2)\n\n\n\nNamely \\[\n\\begin{pmatrix} x_d \\\\ y_d  \\\\ 1 \\end{pmatrix}  = k^{-1} \\begin{pmatrix} u \\\\ v  \\\\ 1 \\end{pmatrix}\n\\] where \\[\nk^{-1} =  \\begin{pmatrix} 1/f_x & 0 & -c_x/f_x   \\\\  0 & 1/f_y & -c_y/f_y  \\\\ 0 & 0 & 1 \\end{pmatrix}\n\\]\n\np2_distorted_back_projected = ci.to_camera_points(p_image)   # transform form image plane to distorted camera plane\n\nerr_distortion_backprojection_1 = np.linalg.norm(p2_distorted_back_projected-p2_distorted)\nassert err_distortion_backprojection_1 < 1e-5, f'Assertion failed error of unptojection to camera plane [{err_distortion_backprojection_1}] is too large'\n\nThe next step is to undistort the points in the image plane.\n\nsource\n\n\nIntrinsics.undistort_points\n\n Intrinsics.undistort_points (pc_distorted:numpy.ndarray)\n\nUndistort points in the image plane using the inverse of the distortion model for that camera model\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\npc_distorted\nndarray\nDistorted points in the camera plane, shape (N,2)\n\n\nReturns\nndarray\nUndistorted points in the image plane\n\n\n\nI most cases, this procedure involves solving a polynomial equation by Newton iterations. The procedure converges very fast, and we use the OpenCv conventions and restrict the number of iterations to 17.\n\np2_undistorted_back_projected = ci.undistort_points(p2_distorted_back_projected)\n\nerr_undistortion_backprojection_1 = np.linalg.norm(p2_undistorted_back_projected-p2_undistorted)\nassert err_undistortion_backprojection_1 < 1e-5, f'Assertion failed error of unptojection to camera plane [{err_undistortion_backprojection_1}] is too large'\n\nFinally we convert from the undistorted camera plane to the 3D camera coordinate system\n\nTests\n\nimport os\nimport sys\nfrom pathlib import Path\nimport cv2\n\nci = Intrinsics.from_test_model()                         # OPENCV5\nci_cv = Intrinsics.from_test_model(as_full_opencv=True)   # same model as ci but defined as OPENCV modxel with last 3 distortion coeffs = 0\nprint(f'full cv camera model: {ci_cv.camera_model_name}')\n\nprint(f'Test camera of type  {ci.camera_model_name}')\n\n# twopoints\npoints_camera = np.array(\n    [\n        [0.5, 0.5,1.],\n        [0.5,0.5,2.],\n        [0.5,0.5,1.4]\n    ]\n)\n\n\n\np2d_cv, d_cv, is_valid_cv = ci_cv.project_and_distort_points(points_camera)  # OPENCV5 model  not handled by OpenCv functions\np2d, d, is_valid = ci.project_and_distort_points(points_camera)              # FULL_OPENCV model handled by OpenCv functions, same as OPENCV5 since last 3 distortion params are zero\nerr_pts = np.linalg.norm(p2d_cv-p2d)\nerr_d = np.linalg.norm(d_cv-d)\nassert err_pts < 1e-5, f'assersion failed comparing project_and_distort_points points to OpenCv [{err_pts}]'\nassert err_d < 1e-5, f'assersion failed comparing project_and_distort_points disparities to OpenCv [{err_d}]'\n\n# Test 1 : camera2image_points model to OpenCv computation\npimage, disparity, valid = ci.camera2image_points(points_camera)\n\nno_rot = np.array([[0.0], [0.0], [0.0]])\nno_trans = np.array([[0.0], [0.0], [0.0]])\npimage_cv, _ =  cv2.projectPoints(points_camera,                              # project to image\n                           no_rot,\n                           no_trans,\n                           ci.K_3,\n                           ci.distortions)\npimage_cv = pimage_cv.squeeze(1)\n\n# compare mvgutils to output of OpenCv\nerr_test_1 = np.linalg.norm(pimage_cv-pimage)\nassert err_test_1 < 1e-5,  f'assersion failed distance between and OpenCV is too large [{err_test_1}]'\n\n\n# Test 2 : transform from camera pixels to distgorted camera plane and then undistort\npd = ci.to_camera_points(pimage)\npu = ci.undistort_points(pd)\n\nppp = np.expand_dims(pimage,1)\ncv_undistorted =  cv2.undistortPoints(ppp, ci.K_3, ci.distortions).squeeze()\n\nerr_test_2 = np.linalg.norm(pu-cv_undistorted)\nassert err_test_2 < 1e-5, f'assersion failed distance between and OpenCV is too large [{err_test_2}]'\n\nfull cv camera model: FULL_OPENCV\nTest camera of type  OPENCV5"
  },
  {
    "objectID": "plane3d.html",
    "href": "plane3d.html",
    "title": "plane3D",
    "section": "",
    "text": "A 3D plane is defined by the implicit equation \\[\nax + by + cz + d=0\n\\] which we will express as \\[\n\\tt{eq}[0]x + \\tt{eq}[1]y + \\tt{eq}[2]z + \\tt{eq}[3]=0\n\\]\nsource"
  },
  {
    "objectID": "plane3d.html#transformations",
    "href": "plane3d.html#transformations",
    "title": "plane3D",
    "section": "Transformations",
    "text": "Transformations\n\nsource\n\nPlane3d.inject_2D_points\n\n Plane3d.inject_2D_points (p)\n\n\nsource\n\n\nPlane3d.project_3D_points\n\n Plane3d.project_3D_points (p)\n\n\nsource\n\n\nPlane3d.transform_plane\n\n Plane3d.transform_plane (transformation)\n\n\nsource\n\n\nPlane3d.transform_plane\n\n Plane3d.transform_plane (transformation)"
  }
]